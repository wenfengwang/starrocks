---
displayed_sidebar: "Japanese"
---

# Dataphin（データフィン）

Dataphinは、アリババグループのOneDataデータガバナンス手法の内部プラクティスのクラウドベースのアウトプットです。これは、ビッグデータのライフサイクル全体にわたってのデータ統合、構築、管理、利用の一括解決策を提供し、企業がデータガバナンスのレベルを大幅に向上させ、高品質かつ信頼性があり、利便性のある消費、安全かつ経済的な生産が実現可能なエンタープライズレベルのデータミドルプラットフォームを構築することを目指しています。Dataphinは、さまざまなコンピューティングプラットフォームのサポートとスケーラブルなオープンな機能を提供し、さまざまな産業の企業のプラットフォーム技術アーキテクチャと特定の要件を満たすために利用することができます。

StarRocksとDataphinを統合する方法は複数あります。

- データ統合のソースまたは宛先データソースとして。StarRocksからデータを読み込んで他のデータソースにプッシュすることもでき、他のデータソースからデータを引っ張ってStarRocksに書き込むこともできます。

- Flink SQLとDatastream開発のソーステーブル（無限スキャン）、ディメンジョンテーブル（有限スキャン）、またはリザルトテーブル（ストリーミングシンクおよびバッチシンク）として。

- データウェアハウスまたはデータマートとして。StarRocksはコンピュートソースとして登録され、SQLスクリプト開発、スケジューリング、データ品質検出、セキュリティ識別などのデータ研究およびガバナンスのタスクに使用できます。

## データ統合

StarRocksデータソースを作成し、オフライン統合タスクにおいてStarRocksデータソースをソースデータベースまたは宛先データベースとして使用できます。手順は以下のとおりです。

### StarRocksデータソースを作成する

#### 基本情報

![StarRocksデータソースを作成する - 1](../../assets/Dataphin/create_sr_datasource_1.png)

- **名前**: 必須項目。データソースの名前を入力します。中国語の文字、英数字、アンダースコア（_）、ハイフン（-）のみを含めることができます。長さは64文字を超えることはできません。

- **データソースコード**: オプション項目。データソースコードを構成した後は、`data source code.table`または`data source code.schema.table`の形式でデータソース内のFlink SQLを参照できます。対応する環境でデータソースに自動的にアクセスする場合は、`${data source code}.table`または`${data source code}.schema.table`形式を使用します。

  > **注意**
  >
  > 現時点では、MySQL、Hologres、MaxComputeのデータソースのみサポートされています。

- **対応シナリオ**: データソースが適用できるシナリオ。

- **説明**: オプション項目。データソースの簡単な説明を入力できます。最大128文字まで入力できます。

- **環境**: ビジネスデータソースが本番データソースと開発データソースを区別する場合は、**Prod and Dev**を選択します。ビジネスデータソースが本番と開発のデータソースを区別しない場合は、**Prod**を選択します。

- **タグ**: データソースにタグを選択できます。

#### 構成情報

![StarRocksデータソースを作成する - 2](../../assets/Dataphin/create_sr_datasource_2.png)

- **JDBC URL**: 必須項目。形式は `jdbc:mysql://<host>:<port>/<dbname>` です。`host`はStarRocksクラスタのFE（フロントエンド）ホストのIPアドレス、`port`はFEのクエリポート、`dbname`はデータベース名です。

- **ロードURL**: 必須項目。形式は `fe_ip:http_port;fe_ip:http_port` です。`fe_ip`はFE（フロントエンド）のホストで、`http_port`はFEのポートです。

- **ユーザー名**: 必須項目。データベースのユーザー名です。

- **パスワード**: 必須項目。データベースのパスワードです。

#### 上級設定

![StarRocksデータソースを作成する - 3](../../assets/Dataphin/create_sr_datasource_3.png)

- **connectTimeout**: データベースのconnectTimeout（ms）です。デフォルト値は900000ミリ秒（15分）です。

- **socketTimeout**: データベースのsocketTimeout（ms）です。デフォルト値は1800000ミリ秒（30分）です。

### StarRocksデータソースからデータを読み込み、その他のデータソースに書き込む

#### StarRocks入力コンポーネントをオフライン統合タスクキャンバスにドラッグします

![StarRocksからデータを読み込む - 1](../../assets/Dataphin/read_from_sr_datasource_1.png)

#### StarRocks入力コンポーネントの構成

![StarRocksからデータを読み込む - 2](../../assets/Dataphin/read_from_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントのシナリオと位置に基づいて適切な名前を入力します。

- **データソース**: Dataphinで作成されたStarRocksデータソースまたはプロジェクトを選択します。データソースの読み取り権限が必要です。満足するデータソースがない場合は、データソースを追加するか、関連する権限を申請できます。

- **ソーステーブル**: 入力と同じテーブル構造を持つ単一のテーブルまたは複数のテーブルを選択します。

- **テーブル**: ドロップダウンリストからStarRocksデータソース内のテーブルを選択します。

- **分割キー**: 並行処理の構成で使用されます。ソースデータテーブルの列を分割キーとして使用できます。分割キーとしては、主キーまたはインデックス付きの列を推奨します。

- **バッチ数**: 1バッチで抽出されるデータレコードの数です。

- **入力フィルタリング**: オプション項目。

  次の2つの場合には、フィルタ情報を入力する必要があります：
  
  - 特定のデータの一部をフィルタリングしたい場合。
  - 日々データを増分的に追加したり、全データを取得する必要がある場合は、Dataphinコンソールのシステム時刻を設定した日付を入力する必要があります。例えば、StarRocksの取引テーブルで、取引作成日を`${bizdate}`として設定したい場合です。

- **出力フィールド**: 入力テーブル情報に基づいて関連するフィールドをリストアップします。再度フィールドをリネーム、削除、追加、移動できます。通常、フィールドは再度リネームされ、ダウンストリームデータの読みやすさを向上させたり、出力時にフィールドをマッピングしやすくしたりします。関連するフィールドがアプリケーションシナリオで必要でないため、入力段階でフィールドを削除することもあります。フィールドの順序を変更して、複数の入力データを効果的にマージしたり、下流側で出力データをマッピングする場合に備えます。

#### 宛先データソースとして出力コンポーネントを選択し構成します

![StarRocksからデータを読み込む - 3](../../assets/Dataphin/read_from_sr_datasource_3.png)

### 他のデータソースからデータを読み込み、StarRocksデータソースに書き込む

#### オフライン統合タスク内の入力コンポーネントを構成し、宛先データソースとしてStarRocks出力コンポーネントを選択して構成します

![StarRocksにデータを書き込む - 1](../../assets/Dataphin/write_to_sr_datasource_1.png)

#### StarRocks出力コンポーネントの構成

![StarRocksにデータを書き込む - 2](../../assets/Dataphin/write_to_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントのシナリオと位置に基づいて適切な名前を入力します。

- **データソース**: StarRocksで作成されたDataphinデータソースまたはプロジェクトを選択します。構成担当者が同期書き込み権限を持つデータソースを選択します。満足するデータソースがない場合は、データソースを追加するか、関連する権限を申請できます。

- **テーブル**: ドロップダウンリストからStarRocksデータソース内のテーブルを選択します。

- **ワンクリックでターゲットテーブルを生成**: StarRocksデータソース内にターゲットテーブルを作成していない場合、上流から読み取ったフィールドの名前、タイプ、備考を自動的に取得し、テーブル作成ステートメントを生成できます。

- **CSVインポート列区切り記号**: StreamLoad CSVをインポートする際に、CSVインポート列の区切り記号を構成できます。デフォルト値は`\t`です。ここではデフォルト値を指定しないでください。データ自体に`\t`が含まれている場合は、他の文字を区切り記号として使用する必要があります。

- **CSVインポート行区切り記号**: StreamLoad CSVをインポートする際に、CSVインポート行の区切り記号を構成できます。デフォルト値は`\n`です。ここではデフォルト値を指定しないでください。データ自体に`\n`が含まれている場合は、他の文字を区切り記号として使用する必要があります。

- **パースソリューション**: オプション項目。データが書き込まれる前後のいくつかの特殊処理です。データがStarRocksデータソースに書き込まれる前に準備ステートメントが実行され、データが書き込まれた後に完了ステートメントが実行されます。

- **フィールドマッピング**: フィールドを手動で選択してマッピングするか、上流の入力フィールドと宛先テーブルのフィールドに基づいて複数のフィールドを一度に処理するための名前ベースまたは位置ベースのマッピングを使用できます。

## リアルタイム開発

### 簡単な紹介

StarRocksは高速かつスケーラブルなリアルタイム解析データベースです。リアルタイムデータ分析とクエリのニーズを満たすために読み書きするリアルタイムコンピューティングで一般的に使用されます。エンタープライズのリアルタイムコンピューティングシナリオで広く使用されています。リアルタイムビジネスモニタリングおよび分析、リアルタイムユーザー行動分析、リアルタイム広告入札システム、リアルタイムリスク管理、不正防止、リアルタイム監視および早期警告などのアプリケーションシナリオで使用できます。企業はリアルタイムでデータを分析・クエリすることで、迅速にビジネス状況を把握し、意思決定を最適化し、より良いサービスを提供し、自らの利益を守ることができます。

### StarRocksコネクタ

StarRocksコネクタは以下の情報をサポートしています：

| **カテゴリ**                                           | **内容**                                   |
| ------------------------------------------------------ | ------------------------------------------ |

| サポートされるタイプ                           | ソーステーブル、ディメンションテーブル、結果テーブル |
| 実行モード                                    | ストリームモードとバッチモード                         |
| データフォーマット                             | JSON および CSV                                      |
| 特別なメトリクス                             | なし                                                  |
| API タイプ                                    | Datastream および SQL                                |
| 結果テーブル内のデータの更新または削除をサポートしますか？ | はい                                                  |

### 使用方法

Dataphin は、StarRocks データソースをリアルタイム計算の読み込みおよび書き込みターゲットとしてサポートしています。StarRocks メタテーブルを作成し、それらをリアルタイム計算タスクに使用できます。

#### StarRocks メタテーブルを作成する

1. **Dataphin** > **R&D** > **開発** > **テーブル** に移動します。

2. **作成** をクリックし、リアルタイム計算テーブルを選択します。

   ![StarRocks メタテーブルを作成する - 1](../../assets/Dataphin/create_sr_metatable_1.png)

   - **テーブルタイプ**: **メタテーブル** を選択します。

   - **メタテーブル**: メタテーブルの名前を入力します。名前は変更できません。

   - **データソース**: StarRocks データソースを選択します。

   - **ディレクトリ**: テーブルを作成するディレクトリを選択します。

   - **説明**: オプションです。

   ![StarRocks メタテーブルを作成する - 2](../../assets/Dataphin/create_sr_metatable_2.png)

3. メタテーブルを作成した後、データソースの編集、ソーステーブル、メタテーブルのフィールドの編集、メタテーブルのパラメータの構成などを行うことができます。

   ![StarRocks メタテーブルを編集する](../../assets/Dataphin/edit_sr_metatable_1.png)

4. メタテーブルを提出します。

#### Kafka から StarRocks にリアルタイムでデータを書き込む Flink SQL タスクを作成する

1. **Dataphin** > **R&D** > **開発** > **計算タスク** に移動します。

2. **Flink SQL タスクの作成** をクリックします。

   ![Flink SQL タスクの作成 - ステップ 2](../../assets/Dataphin/create_flink_task_step2.png)

3. Flink SQL コードを編集し、コンパイルします。 Kafka メタテーブルは入力テーブルとして使用され、StarRocks メタテーブルは出力テーブルとして使用されます。

   ![Flink SQL タスクの作成 - ステップ 3 - 1](../../assets/Dataphin/create_flink_task_step3-1.png)
​   ![Flink SQL タスクの作成 - ステップ 3 - 2](../../assets/Dataphin/create_flink_task_step3-2.png)

4. プレコンパイルが成功した後、デバッグしてコードを提出できます。

5. 開発環境でのテストは、ログの出力とテストテーブルの書き込みを行うことができます。テストテーブルはメタテーブル > プロパティ > デバッグテスト構成で設定できます。

   ![Flink SQL タスクの作成 - ステップ 5 - 1](../../assets/Dataphin/create_flink_task_step5-1.png)
   ![Flink SQL タスクの作成 - ステップ 5 - 2](../../assets/Dataphin/create_flink_task_step5-2.png)

6. 開発環境でタスクが正常に実行された後、タスクと使用されたメタテーブルを本番環境に公開できます。

   ![Flink SQL タスクの作成 - ステップ 6](../../assets/Dataphin/create_flink_task_step6.png)

7. プロダクション環境でタスクを開始して、Kafka から StarRocks にリアルタイムでデータを書き込むことができます。実行中の解析のステータスとログを表示して、タスクの実行ステータスに関する情報を確認したり、タスクの監視アラートを設定したりすることができます。

   ![Flink SQL タスクの作成 - ステップ 7 - 1](../../assets/Dataphin/create_flink_task_step7-1.png)
   ![Flink SQL タスクの作成 - ステップ 7 - 2](../../assets/Dataphin/create_flink_task_step7-2.png)

## データウェアハウスまたはデータマート

### 前提条件

- StarRocks のバージョンが 3.0.6 以降であること。

- Dataphin がインストールされており、Dataphin バージョンが 3.12 以降であること。

- 統計情報の収集が有効になっている必要があります。StarRocks のインストール後、収集はデフォルトで有効になっています。詳細については、[CBO の統計情報を収集する](../../using_starrocks/Cost_based_optimizer.md) を参照してください。

- StarRocks の内部カタログ（デフォルトのカタログ）がサポートされており、外部カタログがサポートされていないこと。

### 接続構成

#### メタデータウェアハウスの設定

Dataphin は、テーブルの使用状況やメタデータの変更を含む情報をメタデータに基づいて表示および表示できます。StarRocks を使用してメタデータを処理および計算できます。そのため、使用する前にメタデータコンピューティングエンジン（メタデータウェアハウス）を初期化する必要があります。手順は次のとおりです。

1. 管理者アカウントを使用して、Dataphin のメタデータウェアハウステナントにログインします。

2. 管理 > システム > メタデータウェアハウス構成 に移動します。

   a. 開始 をクリックします。

   b. StarRocks を選択します。

   c. パラメータを構成します。テスト接続に合格した後、次をクリックします。

   d. メタウェアハウスの初期化を完了します。

   ![メタデータウェアハウスの設定](../../assets/Dataphin/metadata_warehouse_settings_1.png)

パラメータは次のように記述されます:

- **JDBC URL**：JDBC 接続文字列で、2 つの部分に分かれています。

  - Part I: フォーマットは `jdbc:mysql://<Host>:<Port>/` です。`Host` は StarRocks クラスタの FE ホストの IP アドレスです。`Port` は FE のクエリポートです。デフォルト値: `9030`。

  - Part Two: フォーマットは `database? key1 = value1 & key2 = value2` で、`database` はメタデータ計算に使用される StarRocks データベースの名前です（必須）。`?` の後のパラメータはオプションです。

- **Load URL**：フォーマットは `fe_ip:http_port;fe_ip:http_port` です。`fe_ip` は FE（フロントエンド）のホストで、`http_port` は FE のポートです。

- **Username**：StarRocks に接続する際に使用するユーザー名です。

  ユーザーは、JDBC URL で指定されたデータベースに対する読み書き権限を持ち、次のデータベースおよびテーブルにアクセス権限を持っている必要があります:

  - Information Schema 内のすべてのテーブル

  - _statistics_.column_statistics

  - _statistics_.table_statistic_v1

- **Password**：StarRocks のリンクのパスワードです。

- **メタプロジェクト**：Dataphin でメタデータ処理に使用されるプロジェクトの名前です。Dataphin システム内でのみ使用されます。プロジェクト名として `dataphin_meta` を推奨します。

#### StarRocks プロジェクトの作成とデータ開発の開始

データ開発を開始するには、次の手順に従います:

1. 計算設定。

2. StarRocks 計算ソースを作成します。

3. プロジェクトを作成します。

4. StarRocks SQL タスクを作成します。

##### 計算設定

計算設定は、テナントの計算エンジンの種類とクラスタのアドレスを設定します。詳細な手順は次のとおりです:

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. 管理 > システム > 計算構成 に移動します。

3. StarRocks を選択し、次をクリックします。

4. JDBC URL を入力し、検証します。JDBC URL のフォーマットは `jdbc:mysql://<Host>:<Port>/` です。`Host` は StarRocks クラスタの FE ホストの IP アドレスです。`Port` は FE のクエリポートです。デフォルト値: `9030`。

##### StarRocks 計算ソース

計算ソースは、Dataphin のコンセプトです。主な目的は、Dataphin プロジェクトスペースを StarRocks ストレージ計算スペース（データベース）にバインドおよび登録することです。各プロジェクトにつき、計算ソースを作成する必要があります。詳細な手順は次のとおりです:

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. プランニング > エンジン に移動します。

3. 右上隅の **計算エンジンの追加** をクリックして、計算ソースを作成します。

詳細な構成情報は次のとおりです:

1. **基本情報**

   ![計算エンジンの作成 - 1](../../assets/Dataphin/create_compute_engine_1.png)

   - **計算エンジンタイプ**: **StarRocks** を選択します。

   - **計算エンジン名**: 作成するプロジェクトと同じ名前を使用することをお勧めします。開発プロジェクトの場合は、サフィックスに `_dev` を追加します。

   - **説明**: オプションです。計算ソースの説明を入力します。

2. **構成情報**

   ![計算エンジンの作成 - 2](../../assets/Dataphin/create_compute_engine_2.png)

   - **JDBC URL**: フォーマットは `jdbc:mysql://<Host>:<Port>/` です。`Host` は StarRocks クラスタの FE ホストの IP アドレスです。`Port` は FE のクエリポートです。デフォルト値: `9030`。

   - **Load URL**：フォーマットは `fe_ip:http_port;fe_ip:http_port` です。`fe_ip` は FE（フロントエンド）のホストで、`http_port` は FE のポートです。

   - **Username**: StarRocks に接続する際に使用するユーザー名です。

   - **Password**: StarRocks のパスワードです。

- **Task Resource Group**: 異なる優先度を持つタスクに対して異なるStarRocksリソースグループを指定できます。 リソースグループを指定しない場合、StarRocksエンジンは実行するリソースグループを決定します。 リソースグループを指定する場合、Dataphinは異なる優先度を持つタスクを指定されたリソースグループに割り当てます。 SQLタスクのコードまたは論理テーブルの実体化構成でリソースグループが指定されている場合、タスク実行時には計算ソースタスクのリソースグループの構成は無視されます。

   ![コンピュートエンジンの作成 - 3](../../assets/Dataphin/create_compute_engine_3.png)

##### Dataphinプロジェクト

計算ソースを作成した後、それをDataphinプロジェクトにバインドできます。 Dataphinプロジェクトはプロジェクトメンバー、StarRocksストレージおよび計算スペースを管理し、計算タスクを管理および維持します。

Dataphinプロジェクトを作成するには、以下の手順に従ってください。

1. システム管理者またはスーパー管理者としてDataphinにログインします。

2. **Planning** > **Project Management**に移動します。

3. 右上隅の**プロジェクトの作成**をクリックしてプロジェクトを作成します。

4. 基本情報を入力し、前の手順でオフラインエンジンから作成したStarRocksエンジンを選択します。

5. **作成**をクリックします。

##### StarRocks SQL

プロジェクトを作成した後、StarRocks SQLタスクを作成してStarRocks上でDDLまたはDML操作を実行できます。

具体的な手順は次のとおりです。

1. **R & D** > **Develop**に移動します。

2. 右上隅の'+'をクリックしてStarRocks SQLタスクを作成します。

   ![Dataphinプロジェクトの構成 - 1](../../assets/Dataphin/configure_dataphin_project_1.png)

3. 名前とスケジューリングタイプを入力してSQLタスクを作成します。

4. エディタにSQLを入力して、StarRockでDDLおよびDML操作を開始します。

   ![Dataphinプロジェクトの構成 - 2](../../assets/Dataphin/configure_dataphin_project_2.png)