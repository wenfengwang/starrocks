---
displayed_sidebar: "日本語"
---

# Dataphin

Dataphin（データフィン）は、アリババグループのOneDataデータガバナンス手法の内部プラクティスのクラウドベースの成果物です。これは、ビッグデータのライフサイクル全体にわたるデータ統合、構築、管理、利用のためのワンストップソリューションを提供し、企業がデータガバナンスのレベルを大幅に向上させ、高品質で信頼性があり、利便性のある消費、安全で経済的な製品であるエンタープライズレベルのデータミドルプラットフォームを構築することを目指しています。Dataphinは、さまざまな計算プラットフォームのサポートと拡張可能なオープンケイパビリティを提供し、各種業界の企業のプラットフォーム技術アーキテクチャおよび特定の要件を満たします。

StarRocksとDataphinを統合する方法はいくつかあります：

- データ統合のためのソースまたは宛先データソースとして。StarRocksからデータを読み取り、他のデータソースにプッシュしたり、他のデータソースからデータをプルしてStarRocksに書き込むことができます。

- Flink SQLおよびdatastream開発のソーステーブル（無限スキャン）、ディメンションテーブル（有限スキャン）、または結果テーブル（ストリーミングシンクおよびバッチシンク）として。

- データウェアハウスまたはデータマートとして。StarRocksは、SQLスクリプト開発、スケジューリング、データ品質検出、セキュリティ識別など、データの調査やガバナンスタスクに使用できます。

## データ統合

StarRocksデータソースを作成し、オフライン統合タスクでStarRocksデータソースをソースデータベースまたは宛先データベースとして使用できます。手順は次のとおりです：

### StarRocksデータソースを作成

#### 基本情報

![StarRocksデータソースの作成 - 1](../../assets/Dataphin/create_sr_datasource_1.png)

- **名前**：必須。データソースの名前を入力します。中国語の文字、英字、数字、アンダースコア（_）、ハイフン（-）のみが使用できます。64文字を超えることはできません。

- **データソースコード**：オプション。データソースコードを構成した後は、`データソースコード.テーブル`または`データソースコード.スキーマ.テーブル`の形式でデータソース内のFlink SQLを参照できます。対応する環境でデータソースに自動的にアクセスする場合は、`${データソースコード}.table`または`${データソースコード}.スキーマ.table`形式でアクセスします。

  > **注意**
  >
  > 現在、MySQL、Hologres、MaxComputeのデータソースのみがサポートされています。

- **サポートシナリオ**：データソースを適用できるシナリオ。

- **説明**：オプション。データソースの簡単な説明を入力できます。最大128文字まで入力可能です。

- **環境**：ビジネスデータソースが本番データソースと開発データソースを区別する場合は、**本番および開発**を選択します。ビジネスデータソースが本番と開発のデータソースを区別しない場合は、**本番**を選択します。

- **タグ**：データソースにラベルを付けるためのタグを選択できます。

#### 設定情報

![StarRocksデータソースの作成 - 2](../../assets/Dataphin/create_sr_datasource_2.png)

- **JDBC URL**：必須。形式は `jdbc:mysql://<ホスト>:<ポート>/<データベース名>` です。`ホスト`はStarRocksクラスターのFE（フロントエンド）ホストのIPアドレス、`ポート`はFEのクエリポート、`データベース名`はデータベース名です。

- **ロードURL**：必須。形式は `fe_ip:http_port;fe_ip:http_port` です。`fe_ip`はFE（フロントエンド）のホストであり、`http_port`はFEのポートです。

- **ユーザー名**：必須。データベースのユーザー名です。

- **パスワード**：必須。データベースのパスワードです。

#### 高度な設定

![StarRocksデータソースの作成 - 3](../../assets/Dataphin/create_sr_datasource_3.png)

- **connectTimeout**：データベースの接続タイムアウト（ミリ秒単位）。デフォルト値は900000ミリ秒（15分）です。

- **socketTimeout**：データベースのソケットタイムアウト（ミリ秒単位）。デフォルト値は1800000ミリ秒（30分）です。

### StarRocksデータソースからデータを読み取り、他のデータソースにデータを書き込む

#### StarRocks入力コンポーネントをオフライン統合タスクキャンバスにドラッグ

![StarRocksからデータを読み取る - 1](../../assets/Dataphin/read_from_sr_datasource_1.png)

#### StarRocks入力コンポーネントの構成

![StarRocksからデータを読み取る - 2](../../assets/Dataphin/read_from_sr_datasource_2.png)

- **ステップ名**：現在のコンポーネントのシナリオと場所に基づいた適切な名前を入力します。

- **データソース**：StarRocksデータソースまたはDataphinで作成したプロジェクトを選択します。データソースの読み取り権限が必要です。満足するデータソースがない場合は、データソースを追加するか、関連する権限を申請できます。

- **ソーステーブル**：入力と同じテーブル構造を持つ単一のテーブルまたは複数のテーブルを選択します。

- **テーブル**：ドロップダウンリストからStarRocksデータソース内のテーブルを選択します。

- **分割キー**：並行性の構成に使用します。ソースデータテーブルの列を分割キーとして使用できます。分割キーにはプライマリキーまたはインデックス列を使用することをお勧めします。

- **バッチ数**：バッチで抽出されるデータレコードの数です。

- **入力フィルタリング**：オプション。

  次の2つの場合にフィルタ情報を入力する必要があります。

  - 特定のデータの一部をフィルタリングしたい場合。
  - 毎日データを増分的に追加したり、完全なデータを取得する必要がある場合は、Dataphinコンソールのシステム時間として設定された日付を入力する必要があります。たとえば、StarRocksのトランザクションテーブルとそのトランザクション作成日が`${bizdate}`と設定されているとします。

- **出力フィールド**：入力テーブル情報に基づいて関連するフィールドをリストアップします。フィールドを再度名前を変更したり、除去したり、追加したり、移動したりできます。一般的に、後続のデータの可読性を向上させるか、出力時にフィールドのマッピングを容易にするためにフィールドを名前変更します。関連フィールドがアプリケーションシナリオで不要な場合は、入力段階でフィールドを削除できます。フィールドの順序を変更して、複数の入力データを効果的にマージしたり、下流側で出力データをマップしたりできるようにするために、同じ行内で異なる名前のフィールドをマッピングすることができます。

#### 宛先データソースとして出力コンポーネントを選択および構成

![StarRocksからデータを読み取る - 3](../../assets/Dataphin/read_from_sr_datasource_3.png)

### 他のデータソースからデータを読み取り、StarRocksデータソースにデータを書き込む

#### オフライン統合タスクで入力コンポーネントを構成し、StarRocks出力コンポーネントを選択および構成

![StarRocksにデータを書き込む - 1](../../assets/Dataphin/write_to_sr_datasource_1.png)

#### StarRocks出力コンポーネントの構成

![StarRocksにデータを書き込む - 2](../../assets/Dataphin/write_to_sr_datasource_2.png)

- **ステップ名**：現在のコンポーネントのシナリオと場所に基づいた適切な名前を入力します。

- **データソース**：StarRocksで作成されたDataphinデータソースまたはプロジェクトを選択します。構成担当者が同期書き込み権限を持っているデータソースです。満足するデータソースがない場合は、データソースを追加するか、関連する権限を申請できます。

- **テーブル**：ドロップダウンリストからStarRocksデータソース内のテーブルを選択します。

- **ワンクリックでターゲットテーブルを生成する**：StarRocksデータソースでターゲットテーブルを作成していない場合は、上流から読み取ったフィールドの名前、タイプ、および備考を自動的に取得し、テーブル作成ステートメントを生成します。ワンクリックでターゲットテーブルを生成するには、クリックします。

- **CSVインポート列デリミター**：StreamLoad CSVをインポートする際に使用します。CSVインポート列デリミターを構成できます。デフォルト値は `\t` です。ここにデフォルト値を指定しないでください。データ自体に `\t` が含まれている場合は、他の文字をデリミターとして使用する必要があります。

- **CSVインポート行デリミター**：StreamLoad CSVをインポートする際に使用します。CSVインポート行デリミターを構成できます。デフォルト値は `\n` です。ここにデフォルト値を指定しないでください。データ自体に `\n` が含まれている場合は、他の文字をデリミターとして使用する必要があります。

- **解析ソリューション**：オプション。データが書き込まれる前または後に行われる特別な処理です。データがStarRocksデータソースに書き込まれる前に準備ステートメントが実行され、データが書き込まれた後に完了ステートメントが実行されます。

- **フィールドマッピング**：手動でフィールドを選択してマッピングしたり、上流の入力フィールドと宛先テーブルのフィールドをネームベースやポジションベースで一括処理することができます。

## リアルタイム開発

### 簡単な紹介

StarRocksは高速で拡張性のあるリアルタイム分析データベースです。リアルタイムコンピューティングに普及しており、リアルタイムデータ分析とクエリのニーズを満たすためにデータの読み書きが可能です。企業のリアルタイムコンピューティングシナリオで広く使用されています。リアルタイムビジネスモニタリングと分析、リアルタイムユーザー行動分析、リアルタイム広告入札システム、リアルタイムリスク管理、不正防止、リアルタイムモニタリングおよび早期警告などのアプリケーションシナリオで幅広く使用されます。リアルタイムでデータを分析・クエリすることにより、企業は迅速にビジネス状況を把握し、意思決定を最適化し、より良いサービスを提供し、利益を守ることができます。

### StarRocksコネクタ

StarRocksコネクタでは、以下の情報がサポートされています：

| **カテゴリ**           | **内容**                |
| ---------------------- | ----------------------- |
| サポートされているタイプ | ソーステーブル、ディメンションテーブル、結果テーブル |
| 実行モード | ストリームモードおよびバッチモード |
| データフォーマット | JSONおよびCSV |
| 特別なメトリクス | なし |
| APIタイプ | DatastreamおよびSQL |
| 結果テーブルでのデータの更新または削除をサポートしていますか？ | はい |

### 使い方

Dataphinはリアルタイム計算の読み込みおよび書き込み先としてStarRocksデータソースをサポートしています。StarRocksメタテーブルを作成し、リアルタイム計算タスクに使用できます。

#### StarRocksメタテーブルの作成

1. **Dataphin** > **R＆D** > **開発** > **テーブル**に移動します。

2. **作成**をクリックしてリアルタイム計算テーブルを選択します。

   ![StarRocksメタテーブルの作成 - 1](../../assets/Dataphin/create_sr_metatable_1.png)

   - **テーブルタイプ**：**メタテーブル**を選択します。

   - **メタテーブル**：メタテーブルの名前を入力します。名前は不変です。

   - **データソース**：StarRocksデータソースを選択します。

   - **ディレクトリ**：テーブルを作成したいディレクトリを選択します。

   - **説明**：オプションです。

   ![StarRocksメタテーブルの作成 - 2](../../assets/Dataphin/create_sr_metatable_2.png)

3. メタテーブルを作成した後、データソース、ソーステーブル、メタテーブルフィールドの変更、およびメタテーブルパラメータの構成を含むメタテーブルを編集できます。

   ![StarRocksメタテーブルの編集](../../assets/Dataphin/edit_sr_metatable_1.png)

4. メタテーブルを提出します。

#### KafkaからStarRocksへのデータ書き込みのためのFlink SQLタスクの作成

1. **Dataphin** > **R＆D** > **開発** > **計算タスク**に移動します。

2. **Flink SQLタスクの作成**をクリックします。

   ![Flink SQLタスクの作成 - ステップ2](../../assets/Dataphin/create_flink_task_step2.png)

3. Flink SQLコードを編集し、事前コンパイルします。 Kafkaメタテーブルは入力テーブルとし、StarRocksメタテーブルを出力テーブルとします。

   ![Flink SQLタスクの作成 - ステップ3 - 1](../../assets/Dataphin/create_flink_task_step3-1.png)
   ![Flink SQLタスクの作成 - ステップ3 - 2](../../assets/Dataphin/create_flink_task_step3-2.png)

4. 事前コンパイルが成功したら、コードをデバッグおよび提出できます。

5. 開発環境でのテストは、ログの出力およびテストテーブルの作成により行うことができます。テストテーブルはメタテーブル > プロパティ > デバッグテスト構成に設定できます。

   ![Flink SQLタスクの作成 - ステップ5 - 1](../../assets/Dataphin/create_flink_task_step5-1.png)
   ![Flink SQLタスクの作成 - ステップ5 - 2](../../assets/Dataphin/create_flink_task_step5-2.png)

6. 開発環境でのタスクが正常に実行された場合、タスクおよび使用されたメタテーブルを本番環境に公開できます。

   ![Flink SQLタスクの作成 - ステップ6](../../assets/Dataphin/create_flink_task_step6.png)

7. プロダクション環境でタスクを開始し、KafkaからStarRocksへのデータをリアルタイムで書き込むことができます。各メトリックのステータスとログを表示してタスクの実行ステータスを確認したり、タスクの監視アラートを構成することもできます。

   ![Flink SQLタスクの作成 - ステップ7 - 1](../../assets/Dataphin/create_flink_task_step7-1.png)
   ![Flink SQLタスクの作成 - ステップ7 - 2](../../assets/Dataphin/create_flink_task_step7-2.png)

## データウェアハウスまたはデータマート

### 前提条件

- StarRocksのバージョンは3.0.6以上であること。

- Dataphinがインストールされており、Dataphinのバージョンが3.12以上であること。

- 統計データの収集が有効であること。 StarRocksがインストールされた後、デフォルトで収集が有効になります。詳細については、[CBOの統計データの収集](../../using_starrocks/Cost_based_optimizer.md)を参照してください。

- StarRocksの内部カタログ（デフォルトカタログ）がサポートされており、外部カタログはサポートされていないこと。

### 接続構成

#### メタデータウェアハウスの設定

Dataphinは、テーブルの使用状況やメタデータの変更などの情報をメタデータに基づいて表示および表示できます。StarRocksを使用してメタデータを処理および計算できます。そのため、使用する前にメタデータ計算エンジン（メタデータウェアハウス）を初期化する必要があります。手順は次のとおりです。

1. 管理者アカウントを使用してDataphinメタデータウェアハウステナントにログオンします。

2. 管理 > システム > メタデータウェアハウス構成に移動します。

   a. [開始]をクリックします。

   b. StarRocksを選択します。

   c. パラメータを構成します。テスト接続に合格したら、[次へ]をクリックします。

   d. メタウェアハウスの初期化を完了します。

   ![メタデータウェアハウスの設定](../../assets/Dataphin/metadata_warehouse_settings_1.png)

パラメータは次のように説明されています：

- **JDBC URL**: JDBC接続文字列で、2つの部分に分かれます：

  - 第1部：形式は `jdbc:mysql://<Host>:<Port>/` です。`Host` はStarRocksクラスターのFEホストのIPアドレスです。 `Port` はFEのクエリポートです。デフォルト値： `9030`。

  - 第2部：形式は `database?key1=value1&key2=value2` です。`database` はメタデータ計算に使用されるStarRocksデータベースの名前であり、必須です。 '?' の後のパラメータはオプションです。

- **Load URL**：形式は `fe_ip:http_port;fe_ip:http_port` です。 `fe_ip` はFE（Front End）のホストであり、 `http_port` はFEのポートです。

- **ユーザー名**: StarRocksに接続するために使用されるユーザー名です。

  ユーザーはJDBC URLで指定されたデータベースに対して読み取りおよび書き込みアクセス権を持ち、次のデータベースおよびテーブルのアクセス権を持っている必要があります。

  - Information Schemaのすべてのテーブル

  - _statistics_.column_statistics

  - _statistics_.table_statistic_v1

- **パスワード**：StarRocksへのリンクのパスワードです。

- **メタプロジェクト**：Dataphinでのメタデータ処理に使用するプロジェクトの名前です。Dataphinシステム内でのみ使用されます。プロジェクト名には`dataphin_meta`を使用することをお勧めします。

#### StarRocksプロジェクトの作成とデータ開発の開始

データ開発を開始するには、次の手順に従います。

1. コンピューティング設定。

2. StarRocksコンピューティングソースの作成。

3. プロジェクトの作成。

4. StarRocks SQLタスクの作成。

##### コンピューティング設定

コンピューティング設定は、テナントのコンピューティングエンジンのタイプとクラスターアドレスを設定します。詳細な手順は次のとおりです。

1. システム管理者またはスーパーシステム管理者としてDataphinにログオンします。

2. 管理 > システム > 計算構成に移動します。

3. StarRocksを選択し、[次へ]をクリックします。

4. JDBC URLを入力して確認します。JDBC URLの形式は `jdbc:mysql://<Host>:<Port>/` です。`Host` はStarRocksクラスターのFEホストのIPアドレスです。 `Port` はFEのクエリポートです。デフォルト値： `9030`。

##### StarRocksコンピューティングソース

コンピューティングソースはDataphinの概念です。主な目的は、DataphinプロジェクトスペースをStarRocksストレージコンピューティングスペース（データベース）にバインドおよび登録することです。各プロジェクトにコンピューティングソースを作成する必要があります。詳細な手順は次のとおりです。

1. システム管理者またはスーパーシステム管理者としてDataphinにログオンします。

2. 計画 > エンジンに移動します。

3. 右上隅にある [コンピューティングエンジンの追加] をクリックして、コンピューティングソースを作成します。

詳細な構成情報は次のとおりです：

1. **必須情報**

   ![コンピューティングエンジンの作成 - 1](../../assets/Dataphin/create_compute_engine_1.png)

   - **コンピューティングエンジンタイプ**：**StarRocks**を選択します。

   - **コンピューティングエンジン名**：作成するプロジェクトと同じ名前を使用することをお勧めします。開発プロジェクトの場合、サフィックスに `_dev` を追加します。

   - **説明**：オプションです。コンピューティングソースの説明を入力します。

2. **構成情報**

   ![コンピューティングエンジンの作成 - 2](../../assets/Dataphin/create_compute_engine_2.png)

   - **JDBC URL**：形式は `jdbc:mysql://<Host>:<Port>/` です。`Host` はStarRocksクラスターのFEホストのIPアドレスです。 `Port` はFEのクエリポートです。デフォルト値： `9030`。

   - **Load URL**：形式は `fe_ip:http_port;fe_ip:http_port` です。 `fe_ip` はFE（Front End）のホストであり、 `http_port` はFEのポートです。

   - **ユーザー名**：StarRocksに接続するために使用されるユーザー名です。

   - **パスワード**：StarRocksのパスワードです。
- **タスクリソースグループ**: 異なる優先度を持つタスクに対して異なるStarRocksリソースグループを指定できます。リソースグループを指定しない場合、StarRocksエンジンは実行するリソースグループを決定します。リソースグループを指定する場合、Dataphinによって異なる優先度を持つタスクは指定されたリソースグループに割り当てられます。SQLタスクのコードや論理テーブルのマテリアライズド構成でリソースグループが指定されている場合、タスクの実行時にはコンピュートソースタスクのリソースグループの構成は無視されます。

   ![コンピュートエンジンを作成 - 3](../../assets/Dataphin/create_compute_engine_3.png)

##### Dataphinプロジェクト

計算ソースを作成した後、その計算ソースをDataphinプロジェクトにバインドできます。Dataphinプロジェクトは、プロジェクトメンバー、StarRocksストレージおよび計算スペースを管理し、計算タスクを管理および維持します。

Dataphinプロジェクトを作成するには、以下の手順に従ってください。

1. システム管理者またはスーパー管理者としてDataphinにログインします。

2. **プランニング** > **プロジェクト管理**に移動します。

3. 右上隅の**プロジェクトの作成**をクリックしてプロジェクトを作成します。

4. 基本情報を入力し、前の手順で作成されたStarRocksエンジンをオフラインエンジンから選択します。

5. **作成**をクリックします。

##### StarRocks SQL

プロジェクトを作成した後、StarRocks SQLタスクを作成してStarRocks上でDDLまたはDML操作を実行できます。

具体的な手順は以下の通りです。

1. **R & D** > **開発**に移動します。

2. 右上隅の「+」をクリックしてStarRocks SQLタスクを作成します。

   ![Dataphinプロジェクトの構成 - 1](../../assets/Dataphin/configure_dataphin_project_1.png)

3. 名前とスケジューリングタイプを入力して、SQLタスクを作成します。

4. エディタにSQLを入力して、StarRocks上でのDDLおよびDML操作を開始します。

   ![Dataphinプロジェクトの構成 - 2](../../assets/Dataphin/configure_dataphin_project_2.png)