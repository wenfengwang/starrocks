---
displayed_sidebar: "Japanese"
---

# アーキテクチャ

StarRocksはシンプルなアーキテクチャを持っています。システム全体は、フロントエンド（FE）とバックエンド（BE）またはコンピュートノード（CN）の2種類のコンポーネントで構成されています。StarRocksは外部コンポーネントに依存しないため、展開とメンテナンスが簡素化されます。ノードはサービス停止時間なしで水平スケーリングできます。さらに、StarRocksはメタデータとサービスデータのレプリカメカニズムを持っており、データの信頼性を高め、シングルポイントオブフェイル（SPOF）を効率的に防止します。

StarRocksはMySQLプロトコルと互換性があり、標準SQLをサポートしています。ユーザーはMySQLクライアントから簡単にStarRocksに接続して、即座に有益な情報を得ることができます。

## アーキテクチャの進化

StarRocksは進化を続けるにつれ、システムアーキテクチャは元々のストレージ-計算結合アーキテクチャ（共有なし）からストレージ-計算分離アーキテクチャ（共有データ）に移行しています。

- バージョン3.0より前、StarRocksはストレージ-計算結合アーキテクチャを使用しています。BEはデータのストレージと計算の両方を担当します。データアクセスと計算はローカルノードで実行され、データ移動を最小限に抑え、クエリのレイテンシを低減することで、超高速なクエリと分析の体験を提供します。

- バージョン3.0以降、StarRocksはストレージ-計算分離アーキテクチャを導入しています。データストレージはBEから分離され、BEはステートレスのCNノードにアップグレードされます。データはリモートオブジェクトストレージやHDFSに永続的に保存され、CNのローカルディスクはホットデータのキャッシュに使用され、クエリの高速化に寄与します。ストレージ-計算分離アーキテクチャはコンピュートノードのダイナミックな追加と削除をサポートし、オンデマンドでスケーリングが可能です。

次の図はアーキテクチャの進化を示しています。

![アーキテクチャの進化](../assets/architecture_evolution.png)

## ストレージ-計算結合

StarRocksはバージョン3.0以前の典型的な大規模並列処理（MPP）データベースとして、ストレージ-計算結合アーキテクチャを使用しています。このアーキテクチャでは、BEはデータのストレージと計算の両方を担当します。BEモードでのローカルデータへの直接アクセスにより、ローカル計算が可能となり、データ転送やデータコピーを回避し、超高速なクエリと分析のパフォーマンスを提供します。このアーキテクチャはマルチレプリカデータストレージをサポートし、高並行性のクエリを処理するクラスタの能力を向上させ、データの信頼性を確保します。最適なクエリパフォーマンスを求めるシナリオに適しています。

### ノード

ストレージ-計算結合アーキテクチャでは、StarRocksは2種類のノード、FEとBEで構成されています。

- FEはメタデータ管理と実行計画の構築を担当します。
- BEはクエリプランの実行とデータの保存を担当します。BEはローカルストレージを使用してクエリの高速化を図り、マルチレプリカメカニズムを使用してデータの高い可用性を保証します。

### FE

FEはメタデータ管理、クライアント接続管理、クエリの計画、クエリのスケジューリングを担当します。各FEはメモリに完全なメタデータのコピーを保存・維持し、FE間での無差別なサービスを保証します。FEはリーダー、フォロワー、オブザーバーとして機能することができます。フォロワーはPaxosライクなBDB JEプロトコルに従ってリーダーを選出します。BDB JEはBerkeley DB Java Editionの略称です。

| **FEの役割**   | **メタデータ管理**                                                 | **リーダー選出**                                                 |
| -------------  | ------------------------------------------------------------ | ------------------------------------------------------------ |
| リーダーFE      | リーダーFEはメタデータの読み書きを担当します。フォロワーとオブザーバーFEはメタデータの読み取りのみが可能です。彼らはメタデータの書き込みリクエストをリーダーFEにルーティングします。リーダーFEはメタデータを更新し、BDE JEを使用してフォロワーとオブザーバーFEにメタデータの変更を同期します。メタデータの変更がフォロワーFEの半数以上に同期された後、データの書き込みは成功と見なされます。 | リーダーFEはフォロワーFEから選出されます。リーダー選出を行うためには、クラスタ内のフォロワーFEの半数以上がアクティブである必要があります。リーダーFEが失敗した場合、フォロワーFEはリーダー選出を再開します。 |
| フォロワーFE    | フォロワーはメタデータの読み取りのみが可能です。彼らはリーダーFEからログを同期し、メタデータを更新します。 | フォロワーはリーダー選出に参加します。リーダー選出には、クラスタ内のフォロワーの半数以上が必要です。 |
| オブザーバーFE  | オブザーバーはリーダーFEからログを同期し、メタデータを更新します。 | オブザーバーはクラスタのクエリ並行性を向上させるために主に使用されます。オブザーバーはリーダー選出に参加せず、クラスタにリーダー選出の圧力をかけません。 |

### BE

BEはデータの保存とSQLの実行を担当します。

- データの保存: BEは同等のデータの保存機能を持っています。FEは事前に定義されたルールに基づいてデータをBEに分散します。BEはデータを変換し、必要な形式でデータを書き込み、データに対してインデックスを生成します。

- SQLの実行: SQLクエリが到着すると、FEはクエリの意味に基づいて論理実行計画に変換し、BEで実行可能な物理実行計画に変換します。目的のデータを保存しているBEはクエリを実行します。これによりデータの転送やコピーが不要となり、高いクエリパフォーマンスが実現されます。

### データ管理

StarRocksはカラム指向データベースシステムです。データはパーティショニングとバケッティングの仕組みを使用して管理されます。テーブル内のデータはまず複数のパーティションに分割され、その後複数のタブレットに分割されます。タブレットはStarRocksのデータ管理の基本的な論理単位です。各タブレットには複数のレプリカがあり、それらは異なるBEに保存できます。タブレットの数を指定し、StarRocksにタブレットの管理を任せることができます。

パーティションとタブレットにより、テーブルスキャンが減少し、クエリの並行性が向上します。レプリカはデータのバックアップと復元を容易にし、データの損失を防ぎます。

以下の図では、テーブルが時間に基づいて4つのパーティションに分割されています。最初のパーティションのデータはさらに4つのタブレットに分割されます。各タブレットには3つのレプリカがあり、それぞれ異なるBEに保存されています。

![データ管理](../assets/data_manage.png)

1つのテーブルが複数のタブレットに分割されているため、StarRocksは一つのSQL文をすべてのタブレットに並列処理のためにスケジュールすることができます。これにより、複数の物理マシンとコアの計算能力を最大限に活用することができます。また、クエリのプレッシャーを複数のノードにオフロードすることで、サービスの可用性を高めます。高い並行性を実現するため、必要に応じて物理マシンを追加できます。

タブレットの分布は物理ノードに影響を受けません。BEの数が変更された場合（例えば、BEを追加または削除する場合）、現行のサービスは中断することなく継続されます。ノードの変更により、タブレットの自動的な移動がトリガーされます。BEが追加された場合、一部のタブレットは新しいBEに自動的に移動し、データの分布をより均等にします。BEが削除された場合、それらのBE上のタブレットは自動的に他のBEに移動し、レプリカの数が変わらないようにします。自動タブレットの移動により、StarRocksクラスタの自動スケーリングが容易に実現できるようになり、データの再分配を手動で行う必要がありません。

StarRocksはタブレットに対してマルチレプリカメカニズム（デフォルトでは3つ）を使用しています。レプリカにより、データの高い信頼性とサービスの可用性が確保されます。1つのノードの障害が全体のサービスの可用性に影響を与えることはありません。また、レプリカの数を増やすことで、高いクエリの並行性を実現することもできます。

### 制限事項

このアーキテクチャにはいくつかの制約があります。

- 成長コスト: ユーザーは計算とともにストレージをスケーリングする必要があり、望ましくないストレージコストの増加が発生します。データボリュームが増えると、ストレージと計算リソースの需要が不均衡に増加し、リソース効率が低下します。
- 複雑なアーキテクチャ: 複数のレプリカ間でのデータの一貫性を維持することは、システムの複雑さを増し、障害のリスクを高めます。
- 限定的な弾力性: スケーリング操作はデータの再バランスを引き起こし、ユーザーエクスペリエンスの向上に影響を与える可能性があります。

## ストレージ-計算分離

新しいストレージ-計算分離アーキテクチャでは、データストレージ機能がBEから分離されます。BEは「コンピュートノード（CN）」と呼ばれ、データの計算とホットデータのキャッシュのみを担当します。データは低コストで信頼性の高いリモートストレージシステム（例：Amazon S3、GCP、Azure Blob Storage、MinIOなどのS3互換ストレージ）に保存されます。キャッシュがヒットすると、ストレージ-計算結合アーキテクチャと同等のクエリパフォーマンスが得られます。CNノードは数秒で追加または削除することができます。このアーキテクチャはストレージコストを削減し、より良いリソースの分離、高い弾力性、スケーラビリティを確保します。

ストレージ-計算分離アーキテクチャは、ストレージ-計算結合の対応アーキテクチャと同じく、シンプルなアーキテクチャであり、FEとCNの2種類のノードで構成されています。唯一の違いは、バックエンドオブジェクトストレージのプロビジョニングが必要であることです。

![共有データアーキテクチャ](../assets/architecture_shared_data.png)

### ノード

ストレージ-計算分離アーキテクチャのFEは、ストレージ-計算結合アーキテクチャと同じ機能を提供します。

BEのストレージ機能は分離されます。ローカルストレージは共有ストレージに変わります。BEノードはステートレスのCNノードにアップグレードされ、データの読み込み、クエリ計算、キャッシュの管理などのタスクを担当します。

### ストレージ

現在、StarRocksの共有データクラスタはオブジェクトストレージ（例：AWS S3、Google GCS、Azure Blob Storage、MinIO）と従来のデータセンターに展開されたHDFSの2つのストレージソリューションをサポートしています。このテクノロジーにより、指定されたバケットまたはHDFSディレクトリにデータのストレージを統一することができます。

共有データクラスタでは、データファイルの形式は共有なしクラスタ（結合ストレージと計算を特徴とする）と同じになります。データはセグメントファイルに整理され、クラウドネイティブテーブルと呼ばれる共有データクラスタ専用のテーブルで再利用されるインデックス技術が使用されます。

### キャッシュ

StarRocksの共有データクラスタはデータのストレージと計算を分離することで、それぞれを独立してスケーリングすることができます。これにより、コストを削減し、弾力性を高めることができます。ただし、このアーキテクチャはクエリのパフォーマンスに影響を与える可能性があります。

この影響を軽減するために、StarRocksはメモリ、ローカルディスク、リモートストレージを含むマルチティアデータアクセスシステムを確立して、さまざまなビジネスニーズに対応しています。
```markdown
      + Queries against hot data scan the cache directly and then the local disk, while cold data needs to be loaded from the object storage into the local cache to accelerate subsequent queries. By keeping hot data close to compute units, StarRocks achieves truly high-performance computation and cost-effective storage. Moreover, access to cold data has been optimized with data prefetch strategies, effectively eliminating performance limits for queries.

      Users can decide whether to enable caching when creating tables. If caching is enabled, data will be written to both the local disk and backend object storage. During queries, the CN nodes first read data from the local disk. If the data is not found, it will be retrieved from the backend object storage and simultaneously cached on the local disk.
```

```markdown
      + ホットデータに対するクエリは、キャッシュを直接スキャンしてからローカルディスクをスキャンし、一方、コールドデータはオブジェクトストレージからローカルキャッシュに読み込まれ、その後のクエリを高速化します。ホットデータを計算ユニットに近く保つことで、StarRocksは真に高性能な計算とコスト効果の高いストレージを実現しています。さらに、データプリフェッチ戦略により、コールドデータへのアクセスを最適化し、クエリのパフォーマンスの制限を効果的に排除しました。

      ユーザーは、テーブルを作成する際にキャッシュを有効にするかどうかを決定できます。キャッシングが有効になっている場合、データはローカルディスクとバックエンドオブジェクトストレージの両方に書き込まれます。クエリ実行時、CNノードはまずローカルディスクからデータを読み込みます。データが見つからない場合、バックエンドオブジェクトストレージから取得され、同時にローカルディスクにキャッシュされます。
```