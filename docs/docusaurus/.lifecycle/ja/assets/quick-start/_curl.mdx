```
#### `--location-trusted`
この設定は、curlにリダイレクトされたURLに資格情報を渡すように設定します。

#### `-u root`
StarRocksにログインするために使用されるユーザー名です。

#### `-T filename`
Tは転送を意味し、転送するファイル名です。

#### `label:name-num`
このStream Loadジョブに関連付けるラベルです。ラベルはユニークでなければならず、ジョブを複数回実行する場合は、番号を追加してそれを増やすことができます。

#### `column_separator:,`
単一の「,」を使用するファイルをロードする場合は、上記のように設定します。別の区切り文字を使用する場合は、ここでその区切り文字を設定します。一般的な選択肢は「\t」、「,」、「|」です。

#### `skip_header:1`
一部のCSVファイルには、すべての列名がリストされた単一のヘッダー行があり、一部にはデータ型が記載された2行目が追加されています。1つまたは2つのヘッダー行がある場合は、skip_headerを`1`または`2`に設定し、ヘッダー行がない場合は`0`に設定します。

#### `enclose:\"`
埋め込まれたカンマを含む文字列を通常はダブルクォーテーションで囲みます。このチュートリアルで使用されるサンプルデータセットには、カンマが含まれる地理的な位置情報が含まれているため、encloseの設定は`\"`に設定されています。`"`は`\`でエスケープすることを覚えておいてください。

#### `max_filter_ratio:1`
データにいくつかのエラーを許可します。理想的には、これは`0`に設定され、エラーが発生するとジョブが失敗します。デバッグ中にすべての行が失敗するように、`1`に設定されています。

#### `columns:`
CSVファイルの列をStarRocksテーブルの列にマッピングします。CSVファイルにはテーブルに含まれていない列が多く含まれていることに気付くでしょう。テーブルに含まれていない列はスキップされます。

また、crashデータセットの`columns:`行には、データの変換が含まれていることに気付くでしょう。CSVファイルには通常、標準に準拠していない日付や時刻が含まれていることが非常に一般的です。これは、クラッシュの日付と時刻をDATETIMEタイプに変換するためのロジックです。

##### columnsの記述

これは1つのデータレコードの始まりです。日付は`MM/DD/YYYY`形式で、時刻は`HH:MI`です。DATETIMEは一般的に`YYYY-MM-DD HH:MI:SS`なので、このデータを変換する必要があります。

```plaintext
08/05/2014,9:10,BRONX,10469,40.8733019,-73.8536375,"(40.8733019, -73.8536375)",
```

これは`columns:`パラメータの始まりです:

```bash
-H "columns:tmp_CRASH_DATE, tmp_CRASH_TIME, CRASH_DATE=str_to_date(concat_ws(' ', tmp_CRASH_DATE, tmp_CRASH_TIME), '%m/%d/%Y %H:%i')
```

これはStarRocksに対して次のように指示します:
- CSVファイルの最初の列の内容を`tmp_CRASH_DATE`に割り当てる
- CSVファイルの2番目の列の内容を`tmp_CRASH_TIME`に割り当てる
- `concat_ws()`は`tmp_CRASH_DATE`と`tmp_CRASH_TIME`を間にスペースを入れて連結する
- `str_to_date()`は連結した文字列からDATETIMEを作成する
- その結果のDATETIMEを`CRASH_DATE`列に格納する
```