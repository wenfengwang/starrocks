#### StarRocks Stream Loadとcurlには多くの引数があります。 このチュートリアルで使用されるものだけをここで説明し、残りの引数は詳細情報セクションにリンクされます。

#### `--location-trusted`

これにより、curlは認証情報をリダイレクトされたURLに送信します。

#### `-u root`

StarRocksにログインするために使用するユーザー名です。

#### `-T filename`

Tは転送のためのもので、転送するファイル名です。

#### `label:name-num`

このStream Loadジョブに関連付けるラベルです。 ラベルは一意でなければならないため、ジョブを複数回実行する場合は番号を追加して増やすことができます。

#### `column_separator:,`

単一の`,`を使用するファイルをロードする場合は、上記のように設定し、異なる区切り文字を使用する場合はその区切り文字をここで設定します。 一般的な選択肢は`\t`、`,`、および`|`です。

#### `skip_header:1`

一部のCSVファイルには、すべての列名がリストされた単一のヘッダー行が含まれるものと、データ型が2行目に追加されるものがあります。 ヘッダー行が1行または2行ある場合は`1`または`2`に、ヘッダーがない場合は`0`に設定します。

#### `enclose:\"`

埋め込まれたカンマを含む文字列を二重引用符で囲むことが一般的です。 このチュートリアルで使用されるサンプルデータセットには、カンマを含む地理的位置が含まれているため、enclose設定は`\"`に設定されています。 `"\""`を`\`でエスケープすることを忘れないでください。

#### `max_filter_ratio:1`

データ内のエラーを許可します。 理想的には、これを`0`に設定し、エラーが発生するとジョブが失敗します。 デバッグ中にすべての行が失敗するように`1`に設定されています。

#### `columns:`

CSVファイルの列とStarRocksテーブルの列のマッピングです。 CSVファイルにはテーブルに含まれていない多くの列があることに気付くでしょう。 テーブルに含まれていない列はスキップされます。

また、クラッシュデータセットの`columns:`行にデータ変換が含まれていることに気づくでしょう。 CSVファイルには一般的に標準に準拠していない日付や時刻が含まれていることが非常に一般的です。 これはクラッシュの日付と時刻のCSVデータをDATETIMEタイプに変換するロジックです。

##### `columns`行

これは1つのデータレコードの始まりです。 日付は`MM/DD/YYYY`形式で、時間は`HH:MI`です。 DATETIMEは一般に`YYYY-MM-DD HH:MI:SS`ですので、このデータを変換する必要があります。

```plaintext
08/05/2014,9:10,BRONX,10469,40.8733019,-73.8536375,"(40.8733019, -73.8536375)",
```

これは`columns:`パラメータの始まりです:

```bash
-H "columns:tmp_CRASH_DATE, tmp_CRASH_TIME, CRASH_DATE=str_to_date(concat_ws(' ', tmp_CRASH_DATE, tmp_CRASH_TIME), '%m/%d/%Y %H:%i')
```

これはStarRocksに以下を指示します:
- CSVファイルの最初の列の内容を`tmp_CRASH_DATE`に割り当てる
- CSVファイルの2番目の列の内容を`tmp_CRASH_TIME`に割り当てる
- `concat_ws()`は`tmp_CRASH_DATE`と`tmp_CRASH_TIME`を間にスペースを挟んで連結します
- `str_to_date()`は連結された文字列からDATETIMEを作成します
- 作成されたDATETIMEを`CRASH_DATE`列に保存します