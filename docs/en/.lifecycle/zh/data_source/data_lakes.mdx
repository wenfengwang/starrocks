---
displayed_sidebar: English
---
import DataLakeIntro from '../assets/commonMarkdown/datalakeIntro.md'

# 数据湖仓

<DataLakeIntro />

## 关键思想

- 开放数据格式：支持多种数据类型，包括 JSON、Parquet 和 Avro，便于存储和处理结构化和非结构化数据。
- 元数据管理：实现共享元数据层，通常利用 Iceberg 表格式等格式来有效地组织和管理数据。
- 多样化的查询引擎：整合了多个引擎，如 Presto 和 Spark 的增强版本，以满足各种分析和 AI 用例的需求。
- 治理与安全：具备强大的内置机制，用于数据安全、隐私和合规，确保数据完整性和可信度。

## 数据湖仓架构优势

- 灵活性和可扩展性：无缝管理各种数据类型，并根据组织的需求进行扩展。
- 成本效益：为数据存储和处理提供了经济实惠的替代方案，相较于传统方法更具优势。
- 增强数据治理：改进数据控制、管理和完整性，确保可靠、安全的数据处理。
- AI 和分析就绪：非常适合复杂的分析任务，包括机器学习和 AI 驱动的数据处理。

## StarRocks 方法

需要考虑的关键要点包括：

- 与目录或元数据服务集成的标准化
- 计算节点的弹性扩展
- 灵活的缓存机制

---

## 目录

StarRocks 有两种类型的目录，分别是内部目录和外部目录。内部目录包含存储在 StarRocks 数据库中的数据的元数据。外部目录用于处理外部存储的数据，包括由 Hive、Iceberg、Delta Lake 和 Hudi 管理的数据。页面底部的“更多信息”部分提供了其他外部系统的链接。

## 计算节点（CN）扩展

存储和计算的分离降低了扩展的复杂性。由于 StarRocks 计算节点仅存储本地缓存，因此可以根据负载情况添加或删除节点。

## 数据缓存

计算节点上的缓存是可选的。如果计算节点根据快速变化的负载模式快速启动和关闭，或者查询通常仅涉及最新数据，那么缓存数据可能就没有意义了。

## 边学边做

尝试使用基于 Docker 的数据湖仓。本 [数据湖仓教程](../quick_start/iceberg.md) 创建了一个使用 Iceberg 和 MinIO 构建的数据湖，并将 StarRocks 容器连接作为查询引擎。加载提供的数据集，或添加您自己的数据集。

---

import DocCardList from '@theme/DocCardList';

<DocCardList />