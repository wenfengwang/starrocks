---
displayed_sidebar: English
---

# 架构

StarRocks具有简单的架构。整个系统仅由两种类型的组件组成，即前端（FE）和后端（BE）或计算节点（CN）。StarRocks不依赖任何外部组件，简化了部署和维护。节点可以在不影响服务运行的情况下进行水平扩展。此外，StarRocks还具有元数据和业务数据的副本机制，可提高数据可靠性，有效地防止单点故障（SPOF）。

StarRocks兼容MySQL协议，并支持标准SQL。用户可以轻松地从MySQL客户端连接到StarRocks，以获得即时和有价值的见解。

## 架构演进

随着StarRocks的不断发展，系统架构已经从最初的存储-计算耦合架构（无共享）过渡到存储-计算分离架构（共享数据）。

- 在3.0版本之前，StarRocks采用了存储-计算耦合架构。BE负责数据存储和计算。数据访问和计算均在本地节点上进行，以最小化数据移动并降低查询延迟，从而提供了超快的查询和分析体验。

- 从3.0版本开始，StarRocks引入了存储-计算分离架构。数据存储与BE分离，而BE则升级为无状态CN节点。数据持久存储在远程对象存储或HDFS中，而CN的本地磁盘用于缓存热数据以加速查询。存储-计算分离架构支持动态增加和移除计算节点，实现按需扩展和收缩。

下图说明了架构的演进情况。

![架构演进](../assets/architecture_evolution.png)

## 存储-计算耦合

作为典型的大规模并行处理（MPP）数据库，StarRocks在3.0版本之前采用了存储-计算耦合架构。在这种架构中，BE负责数据存储和计算。直接访问BE模式下的本地数据可进行本地计算，避免数据传输和复制，从而实现了超快的查询和分析性能。该架构支持多副本数据存储，增强了集群处理高并发查询的能力，并确保了数据的可靠性。这种架构非常适用于追求最佳查询性能的场景。

### 节点

在存储-计算耦合架构中，StarRocks由两种类型的节点组成：FE和BE。

- FE负责元数据管理和执行计划的构建。
- BE执行查询计划并存储数据。BE利用本地存储加速查询，并利用多副本机制确保数据的高可用性。

### FE

FE负责元数据管理、客户端连接管理、查询规划和查询调度。每个FE在其内存中存储并维护着完整的元数据副本，从而保证了FE之间的无差别服务。FE可以充当领导者、追随者和观察者。追随者可以根据类似Paxos的BDB JE协议选举出领导者。BDB JE是Berkeley DB Java Edition的缩写。

| **FE角色** | **元数据管理**                                               | **领导者选举**                                              |
| ----------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 领导者FE      | 领导者FE读取和写入元数据。追随者和观察者FE只能读取元数据。它们将元数据写入请求路由到领导者FE。领导者FE更新元数据，然后使用BDE JE将元数据更改同步到追随FE和观察者FE。只有当元数据变更同步到一半以上的追随FE后，数据写入才会被视为成功。 | 领导者FE是从追随者FE中选出的。要进行领导者选举，集群中必须有一半以上的追随者FE处于活动状态。当领导者FE失败时，追随者FE将开始新一轮领导者选举。 |
| 追随者FE    | 追随者只能读取元数据。它们同步和重放来自领导者FE的日志以更新元数据。 | 追随者参与领导者选举，这需要集群中一半以上的追随者处于活跃状态。 |
| 观察者FE   | 观察者同步和重放来自领导者FE的日志以更新元数据。     | 观察者主要用于增加集群的查询并发。观察者不参与领导者选举，因此不会给集群增加领导者选择压力。|

### BE

BE负责数据存储和SQL执行。

- 数据存储：BE具有等效的数据存储能力。FE根据预定义的规则将数据分发给BE。BE转换引入的数据，将数据写入所需的格式，并为数据生成索引。

- SQL执行：当SQL查询到达时，FE会根据查询的语义将其解析为逻辑执行计划，然后将逻辑计划转换为可以在BE上执行的物理执行计划。存储目标数据的BE执行查询。这样就无需数据传输和复制，从而实现了高查询性能。

### 数据管理
StarRocks 是一个面向列的数据库系统。它使用分区和存储桶机制来管理数据。表中的数据首先被划分为多个分区，然后被划分为多个 tablet。Tablet 是 StarRocks 中数据管理的基本逻辑单元。每个 tablet 可以有多个副本，这些副本可以存储在不同的 BE 中。您可以指定 tablet 的数量，然后让 StarRocks 来管理这些 tablet。

分区和 tablet 可以减少表扫描并增加查询并发性。副本有助于数据备份和恢复，防止数据丢失。

在下图中，表根据时间被划分为四个分区。第一个分区中的数据进一步被划分为四个 tablet。每个 tablet 都有三个副本，它们存储在三个不同的 BE 上。

![数据管理](../assets/data_manage.png)

由于一个表被划分为多个 tablet，StarRocks 可以将一个 SQL 语句调度到所有 tablet 进行并行处理，充分利用多台物理机和多核的计算能力。这也有助于将查询压力分散到多个节点，提高服务的可用性。您可以根据需要添加物理机，以实现高并发。

tablet 的分布不受物理节点的影响或限制。如果 BE 的数量发生变化（例如，当您添加或删除一个 BE），正在进行的服务可以继续进行而不会中断。节点的变化将触发 tablet 的自动迁移。如果添加了 BE，部分 tablet 将自动迁移到新的 BE，以实现数据分配更均匀。如果删除了 BE，那些 BE 上的 tablet 将自动迁移到其他 BE，确保副本数量不变。自动 tablet 迁移有助于轻松实现 StarRocks 集群的自动扩展，无需手动重新分配数据。

StarRocks 对 tablet 使用多副本机制（默认为 3）。副本保证了数据的高可靠性和业务的可用性。一个节点的故障不会影响整体服务的可用性。您也可以增加副本的数量，以实现更高的查询并发性。

### 局限性

这种架构有其自身的局限性：

- 成本增长：用户必须随着计算规模的扩大而扩展存储，增加了不必要的存储成本。随着数据量的增长，对存储和计算资源的需求增长的不成比例，导致资源利用率低。
- 复杂的架构：在多个副本之间保持数据一致性会增加系统的复杂性，增加了系统故障的风险。
- 有限的弹性：扩展操作会导致数据重新平衡，导致用户体验不佳。

## 存储-计算分离

在新的存储-计算分离架构中，数据存储功能与 BE 解耦。BE 现在被称为“计算节点（CN）”，仅负责数据计算和缓存热数据。数据存储在低成本、可靠的远程存储系统中，例如 Amazon S3、GCP、Azure Blob 存储和其他兼容 S3 的存储，如 MinIO。当缓存命中时，查询性能可与存储-计算耦合架构相媲美。CN 节点可以在几秒内按需添加或删除。这种架构降低了存储成本，确保了更好的资源隔离性，以及高弹性和可扩展性。

存储-计算分离架构与存储-计算耦合架构相比，保持了简单的架构。它只包括两种类型的节点：FE 和 CN。唯一的区别是用户必须配置后端对象存储。

![共享数据架构](../assets/architecture_shared_data.png)

### 节点

存储-计算分离架构中的 FE 提供的功能与存储-计算耦合架构中的相同。

BE 的存储功能被分离出来。本地存储已转变为共享存储。BE 节点升级为无状态的 CN 节点，负责数据加载、查询计算和缓存管理等任务。

### 存储

目前，StarRocks 共享数据集群支持两种存储解决方案：对象存储（例如 AWS S3、Google GCS、Azure Blob 存储和 MinIO）以及部署在传统数据中心的 HDFS。该技术将数据存储在指定的存储桶或 HDFS 目录中。

在共享数据集群中，数据文件格式与无共享集群（具有存储和计算耦合功能）的数据文件格式保持一致。数据被组织成段文件，并且各种索引技术在云原生表中得到重复使用，云原生表是专门用于共享数据集群的表。

### 缓存

StarRocks 的共享数据集群将数据存储和计算解耦，允许二者独立扩展，从而降低成本并增强弹性。但是，这种架构可能会影响查询性能。

为了减轻这种影响，StarRocks 建立了一个多层数据访问系统，包括内存、本地磁盘和远程存储，以更好地满足各种业务需求。

对热数据的查询会直接扫描缓存，然后扫描本地磁盘，而冷数据需要从对象存储加载到本地缓存，以加速后续查询。通过将热数据保持靠近计算单元，StarRocks 实现了真正的高性能计算和高性价比的存储。此外，通过数据预取策略优化了对冷数据的访问，有效消除了查询的性能限制。

用户可以在创建表时决定是否启用缓存。如果启用缓存，数据将同时写入本地磁盘和后端对象存储。在查询过程中，CN节点首先从本地磁盘读取数据。如果未找到数据，将从后端对象存储中检索数据，并同时缓存在本地磁盘上。