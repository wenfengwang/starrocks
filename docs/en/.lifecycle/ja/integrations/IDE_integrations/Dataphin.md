---
displayed_sidebar: "Japanese"
---

# Dataphin

Dataphinは、アリババグループのOneDataデータガバナンス手法のクラウドベースのアウトプットです。ビッグデータのライフサイクル全体にわたるデータ統合、構築、管理、利用のワンストップソリューションを提供し、企業のデータガバナンスのレベルを大幅に向上させ、高品質で信頼性の高いエンタープライズレベルのデータミドルプラットフォームを構築することを目指しています。Dataphinは、さまざまな業界の企業のプラットフォーム技術アーキテクチャと特定の要件を満たすために、さまざまな計算プラットフォームのサポートとスケーラブルなオープンな機能を提供しています。

StarRocksとDataphinを統合する方法はいくつかあります。

- データ統合のソースまたは宛先データソースとして。StarRocksからデータを読み取り、他のデータソースにプッシュすることができます。または、他のデータソースからデータを取得し、StarRocksに書き込むことができます。

- flink SQLおよびdatastream開発のソーステーブル（非境界スキャン）、ディメンションテーブル（境界スキャン）、または結果テーブル（ストリーミングシンクおよびバッチシンク）として。

- データウェアハウスまたはデータマートとして。StarRocksは、計算ソースとして登録でき、SQLスクリプトの開発、スケジューリング、データ品質検出、セキュリティ識別などのデータ研究およびガバナンスのタスクに使用できます。

## データ統合

オフライン統合タスクで、StarRocksデータソースを作成し、StarRocksデータソースをオフライン統合タスクのソースデータベースまたは宛先データベースとして使用できます。手順は次のとおりです。

### StarRocksデータソースを作成する

#### 基本情報

![StarRocksデータソースの作成 - 1](../../assets/Dataphin/create_sr_datasource_1.png)

- **名前**: 必須。データソースの名前を入力します。中国語の文字、英数字、アンダースコア（_）、ハイフン（-）のみを含めることができます。長さは64文字を超えることはできません。

- **データソースコード**: オプション。データソースコードを設定すると、データソース内のFlink SQLを参照するために`データソースコード.テーブル`または`データソースコード.スキーマ.テーブル`の形式を使用できます。対応する環境でデータソースに自動的にアクセスする場合は、`${データソースコード}.テーブル`または`${データソースコード}.スキーマ.テーブル`の形式を使用します。

  > **注意**
  >
  > 現在、MySQL、Hologres、およびMaxComputeのデータソースのみがサポートされています。

- **サポートシナリオ**：データソースが適用できるシナリオ。

- **説明**: オプション。データソースの簡単な説明を入力できます。最大128文字まで入力できます。

- **環境**: ビジネスデータソースが本番データソースと開発データソースを区別する場合は、**Prod and Dev**を選択します。ビジネスデータソースが本番と開発のデータソースを区別しない場合は、**Prod**を選択します。

- **タグ**: データソースにラベルを付けるためにタグを選択できます。

#### 設定情報

![StarRocksデータソースの作成 - 2](../../assets/Dataphin/create_sr_datasource_2.png)

- **JDBC URL**: 必須。形式は`jdbc:mysql://<ホスト>:<ポート>/<データベース名>`です。`ホスト`はStarRocksクラスタのFE（フロントエンド）ホストのIPアドレス、`ポート`はFEのクエリポート、`データベース名`はデータベース名です。

- **Load URL**: 必須。形式は`fe_ip:http_port;fe_ip:http_port`です。`fe_ip`はFE（フロントエンド）のホストで、`http_port`はFEのポートです。

- **ユーザー名**: 必須。データベースのユーザー名です。

- **パスワード**: 必須。データベースのパスワードです。

#### 高度な設定

![StarRocksデータソースの作成 - 3](../../assets/Dataphin/create_sr_datasource_3.png)

- **connectTimeout**: データベースのconnectTimeout（ミリ秒単位）です。デフォルト値は900000ミリ秒（15分）です。

- **socketTimeout**: データベースのsocketTimeout（ミリ秒単位）です。デフォルト値は1800000ミリ秒（30分）です。

### StarRocksデータソースからデータを読み取り、他のデータソースにデータを書き込む

#### StarRocks入力コンポーネントをオフライン統合タスクキャンバスにドラッグします

![StarRocksからデータを読み取る - 1](../../assets/Dataphin/read_from_sr_datasource_1.png)

#### StarRocks入力コンポーネントの設定

![StarRocksからデータを読み取る - 2](../../assets/Dataphin/read_from_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントのシナリオと場所に基づいて適切な名前を入力します。

- **データソース**: StarRocksデータソースまたはDataphinで作成したプロジェクトを選択します。データソースの読み取り権限が必要です。該当するデータソースがない場合は、データソースを追加するか、関連する権限を申請することができます。

- **ソーステーブル**: 入力と同じテーブル構造を持つ単一のテーブルまたは複数のテーブルを選択します。

- **テーブル**: ドロップダウンリストからStarRocksデータソースのテーブルを選択します。

- **分割キー**: 並行性の設定と一緒に使用します。ソースデータテーブルの列を分割キーとして使用できます。分割キーとして主キーまたはインデックス化された列を使用することをお勧めします。

- **バッチ数**: バッチで抽出されるデータレコードの数。

- **入力フィルタリング**: オプション。

  次の2つの場合、フィルタ情報を入力する必要があります。
  
  - 特定のデータの一部をフィルタリングする場合。
  - 毎日データを増分的に追加するか、フルデータを取得する場合は、Dataphinコンソールのシステム時刻として設定された日付を入力する必要があります。たとえば、StarRocksのトランザクションテーブルとその作成日は`${bizdate}`と設定されています。

- **出力フィールド**: 入力テーブル情報に基づいて関連するフィールドをリストします。フィールドを再度リネーム、削除、追加、移動することができます。一般的に、フィールドはリネームされ、下流データの可読性を高めるか、出力時のフィールドのマッピングを容易にするために再度リネームされます。入力ステージでは関連するフィールドが必要ないため、フィールドを削除することができます。フィールドの順序を変更することで、複数の入力データをマージしたり、出力データをマッピングしたりする際に、同じ行内の異なる名前のフィールドをマッピングすることができます。

#### 宛先データソースとしての出力コンポーネントを選択して設定する

![StarRocksからデータを読み取る - 3](../../assets/Dataphin/read_from_sr_datasource_3.png)

### 他のデータソースからデータを読み取り、StarRocksデータソースにデータを書き込む

#### オフライン統合タスクで入力コンポーネントを設定し、宛先データソースとしてStarRocks出力コンポーネントを選択して設定します

![StarRocksにデータを書き込む - 1](../../assets/Dataphin/write_to_sr_datasource_1.png)

#### StarRocks出力コンポーネントの設定

![StarRocksにデータを書き込む - 2](../../assets/Dataphin/write_to_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントのシナリオと場所に基づいて適切な名前を入力します。

- **データソース**: StarRocksデータソースまたはDataphinで作成したプロジェクトを選択します。構成者が同期書き込み権限を持つデータソースが必要です。データソースが満たされていない場合は、データソースを追加するか、関連する権限を申請することができます。

- **テーブル**: ドロップダウンリストからStarRocksデータソースのテーブルを選択します。

- **ワンクリックでターゲットテーブルを生成する**: StarRocksデータソースにターゲットテーブルが作成されていない場合、上流から読み取られたフィールドの名前、タイプ、注釈を自動的に取得し、テーブル作成ステートメントを生成します。ワンクリックでターゲットテーブルを生成するには、クリックします。

- **CSVインポートの列区切り記号**: StreamLoad CSVをインポートする場合、CSVインポートの列区切り記号を設定できます。デフォルト値は`\t`です。ここではデフォルト値を指定しないでください。データ自体に`\t`が含まれる場合は、他の文字を区切り記号として使用する必要があります。

- **CSVインポートの行区切り記号**: StreamLoad CSVをインポートする場合、CSVインポートの行区切り記号を設定できます。デフォルト値は`\n`です。ここではデフォルト値を指定しないでください。データ自体に`\n`が含まれる場合は、他の文字を区切り記号として使用する必要があります。

- **パースソリューション**: オプション。データが書き込まれる前または後に特殊な処理を行います。データがStarRocksデータソースに書き込まれる前に準備ステートメントが実行され、データが書き込まれた後に完了ステートメントが実行されます。

- **フィールドマッピング**: フィールドを手動で選択してマッピングするか、上流の入力フィールドと宛先テーブルのフィールドを基に名前ベースまたは位置ベースのマッピングを使用して複数のフィールドを一度に処理することができます。

## リアルタイム開発

### 簡単な紹介

StarRocksは高速かつスケーラブルなリアルタイム分析データベースです。リアルタイムのデータ分析とクエリのニーズを満たすためにデータの読み書きを行うためによく使用されます。企業のリアルタイムコンピューティングシナリオで広く使用されています。リアルタイムビジネスモニタリングと分析、リアルタイムユーザー行動分析、リアルタイム広告入札システム、リアルタイムリスクコントロール、不正防止、リアルタイムモニタリングと早期警告などのアプリケーションシナリオで広く使用されています。リアルタイムでデータを分析およびクエリすることで、企業は迅速にビジネス状況を把握し、意思決定を最適化し、より良いサービスを提供し、自社の利益を保護することができます。

### StarRocksコネクタ

StarRocksコネクタは、次の情報をサポートしています。

| **カテゴリ**                                           | **事実と数字**                       |
| ------------------------------------------------------ | ------------------------------------------- |
| サポートされるタイプ                                        | ソーステーブル、ディメンションテーブル、結果テーブル |
| 実行モード                                           | ストリームモードおよびバッチモード                  |
| データ形式                                            | JSONおよびCSV                                |
| 特別なメトリクス                                        | なし                                        |
| APIタイプ                                               | データストリームおよびSQL                          |
| 結果テーブルでデータを更新または削除することはできますか？ | はい                                         |

### 使い方

Dataphinは、リアルタイムコンピュートのためのStarRocksデータソースを読み取りおよび書き込みターゲットとしてサポートしています。StarRocksメタテーブルを作成し、リアルタイムコンピュートタスクに使用できます。

#### StarRocksメタテーブルを作成する

1. **Dataphin** > **R & D** > **Develop** > **Tables**に移動します。

2. **Create**をクリックしてリアルタイムコンピュートテーブルを選択します。

   ![StarRocksメタテーブルの作成 - 1](../../assets/Dataphin/create_sr_metatable_1.png)

   - **テーブルタイプ**: **Metatable**を選択します。

   - **Metatable**: メタテーブルの名前を入力します。名前は変更できません。

   - **データソース**: StarRocksデータソースを選択します。

   - **ディレクトリ**: テーブルを作成するディレクトリを選択します。

   - **説明**: オプションです。

   ![StarRocksメタテーブルの作成 - 2](../../assets/Dataphin/create_sr_metatable_2.png)

3. メタテーブルを作成した後、データソース、ソーステーブル、メタテーブルフィールドを編集し、メタテーブルパラメータを設定することができます。

   ![StarRocksメタテーブルの編集](../../assets/Dataphin/edit_sr_metatable_1.png)

4. メタテーブルを提出します。

#### KafkaからStarRocksにリアルタイムでデータを書き込むためのFlink SQLタスクを作成する

1. **Dataphin** > **R & D** > **Develop** > **Computing Tasks**に移動します。

2. **Create Flink SQL task**をクリックします。

   ![Flink SQLタスクの作成 - ステップ2](../../assets/Dataphin/create_flink_task_step2.png)

3. Flink SQLコードを編集し、それを事前コンパイルします。Kafkaメタテーブルを入力テーブルとして使用し、StarRocksメタテーブルを出力テーブルとして使用します。

   ![Flink SQLタスクの作成 - ステップ3 - 1](../../assets/Dataphin/create_flink_task_step3-1.png)
   ![Flink SQLタスクの作成 - ステップ3 - 2](../../assets/Dataphin/create_flink_task_step3-2.png)

4. 事前コンパイルが成功したら、コードをデバッグして提出することができます。

5. 開発環境でテストを行うには、ログを出力したり、テストテーブルにデータを書き込んだりすることができます。テストテーブルは、メタテーブル > プロパティ > デバッグテストの設定で設定できます。

   ![Flink SQLタスクの作成 - ステップ5 - 1](../../assets/Dataphin/create_flink_task_step5-1.png)
   ![Flink SQLタスクの作成 - ステップ5 - 2](../../assets/Dataphin/create_flink_task_step5-2.png)

6. 開発環境でタスクが正常に実行されると、タスクと使用されるメタテーブルを本番環境に公開することができます。

   ![Flink SQLタスクの作成 - ステップ6](../../assets/Dataphin/create_flink_task_step6.png)

7. 本番環境でタスクを開始して、KafkaからStarRocksにリアルタイムでデータを書き込むことができます。実行中の分析の各メトリックのステータスとログを表示して、タスクの実行ステータスについて学ぶか、タスクの監視アラートを設定することができます。

   ![Flink SQLタスクの作成 - ステップ7 - 1](../../assets/Dataphin/create_flink_task_step7-1.png)
   ![Flink SQLタスクの作成 - ステップ7 - 2](../../assets/Dataphin/create_flink_task_step7-2.png)

## データウェアハウスまたはデータマート

### 前提条件

- StarRocksのバージョンは3.0.6以降であること。

- Dataphinがインストールされており、Dataphinのバージョンが3.12以降であること。

- 統計情報の収集が有効になっていること。StarRocksがインストールされた後、収集はデフォルトで有効になっています。詳細については、[CBOのための統計情報の収集](../../using_starrocks/Cost_based_optimizer.md)を参照してください。

- StarRocksの内部カタログ（デフォルトカタログ）がサポートされており、外部カタログはサポートされていないこと。

### 接続の設定

#### メタデータウェアハウスの設定

Dataphinは、テーブルの使用状況やメタデータの変更など、メタデータに基づいた情報を表示および表示することができます。メタデータを処理および計算するためにStarRocksを使用することができます。そのためには、メタデータ計算エンジン（メタデータウェアハウス）を初期化する必要があります。手順は次のとおりです。

1. 管理者アカウントを使用してDataphinメタデータウェアハウステナントにログインします。

2. 管理 > システム > メタデータウェアハウスの設定に移動します。

   a. 開始をクリックします。

   b. StarRocksを選択します。

   c. パラメータを設定します。テスト接続に合格したら、次をクリックします。

   d. メタウェアウェアハウスの初期化を完了します。

   ![メタデータウェアハウスの設定](../../assets/Dataphin/metadata_warehouse_settings_1.png)

パラメータの説明は次のとおりです。

- **JDBC URL**: JDBC接続文字列で、2つの部分に分かれています。

  - パートI: 形式は`jdbc:mysql://<ホスト>:<ポート>/`です。`ホスト`はStarRocksクラスタのFE（フロントエンド）ホストのIPアドレスで、`ポート`はFEのクエリポートです。デフォルト値: `9030`。

  - パートII: 形式は`database? key1 = value1 & key2 = value2`です。`database`はメタデータ計算に使用するStarRocksデータベースの名前で、必須です。`?`の後のパラメータはオプションです。

- **Load URL**：形式は`fe_ip:http_port;fe_ip:http_port`です。`fe_ip`はFE（フロントエンド）のホストで、`http_port`はFEのポートです。

- **ユーザー名**: StarRocksに接続するために使用するユーザー名です。

  ユーザーは、JDBC URLで指定されたデータベースに対して読み取りおよび書き込みの権限を持っている必要があります。また、次のデータベースとテーブルに対してアクセス権限を持っている必要があります。

  - すべてのテーブル情報

  - _statistics_.column_statistics

  - _statistics_.table_statistic_v1

- **パスワード**: StarRocksへのリンクのパスワードです。

- **メタプロジェクト**: Dataphinでメタデータ処理に使用するプロジェクトの名前です。Dataphinシステム内でのみ使用されます。プロジェクト名として`dataphin_meta`を使用することをお勧めします。

#### StarRocksプロジェクトの作成とデータ開発の開始

データ開発を開始するには、次の手順に従います。

1. 計算設定。

2. StarRocks計算ソースを作成します。

3. プロジェクトを作成します。

4. StarRocks SQLタスクを作成します。

##### 計算設定

計算設定では、テナントの計算エンジンのタイプとクラスタのアドレスを設定します。詳細な手順は次のとおりです。

1. システム管理者またはスーパー管理者としてDataphinにログインします。

2. 管理 > システム > 計算設定に移動します。

3. **StarRocks**を選択し、**次へ**をクリックします。

4. JDBC URLを入力し、検証します。JDBC URLの形式は`jdbc:mysql://<ホスト>:<ポート>/`です。`ホスト`はStarRocksクラスタのFEホストのIPアドレスで、`ポート`はFEのクエリポートです。デフォルト値: `9030`。

##### StarRocks計算ソース

計算ソースは、Dataphinの概念です。主な目的は、DataphinプロジェクトスペースをStarRocksストレージ計算スペース（データベース）にバインドおよび登録することです。各プロジェクトには計算ソースを作成する必要があります。詳細な手順は次のとおりです。

1. システム管理者またはスーパー管理者としてDataphinにログインします。

2. プランニング > エンジンに移動します。

3. 右上隅の**Add Computing Engine**をクリックして計算ソースを作成します。

詳細な設定情報は次のとおりです。

1. **必須情報**

   ![計算エンジンの作成 - 1](../../assets/Dataphin/create_compute_engine_1.png)

   - **計算エンジンタイプ**: **StarRocks**を選択します。

   - **計算エンジン名**: プロジェクトの作成と同じ名前を使用することをお勧めします。開発プロジェクトの場合は、サフィックスに`_dev`を追加します。

   - **説明**: オプションです。計算ソースの説明を入力します。

2. **設定情報**

   ![計算エンジンの作成 - 2](../../assets/Dataphin/create_compute_engine_2.png)

   - **JDBC URL**: 形式は`jdbc:mysql://<ホスト>:<ポート>/`です。`ホスト`はStarRocksクラスタのFEホストのIPアドレスで、`ポート`はFEのクエリポートです。デフォルト値: `9030`。

   - **Load URL**：形式は`fe_ip:http_port;fe_ip:http_port`です。`fe_ip`はFE（フロントエンド）のホストで、`http_port`はFEのポートです。

   - **ユーザー名**: StarRocksに接続するために使用するユーザー名です。

   - **パスワード**: StarRocksのパスワードです。

   - **タスクリソースグループ**: 異なる優先度を持つタスクに異なるStarRocksリソースグループを指定できます。リソースグループを指定しない場合、StarRocksエンジンは実行するリソースグループを決定します。リソースグループを指定する場合、Dataphinによって異なる優先度のタスクが指定されたリソースグループに割り当てられます。SQLタスクのコードまたは論理テーブルのマテリアライズド構成でリソースグループが指定されている場合、タスクが実行されるときに、計算ソースタスクのリソースグループの設定は無視されます。

   ![計算エンジンの作成 - 3](../../assets/Dataphin/create_compute_engine_3.png)

##### Dataphinプロジェクト

計算ソースを作成した後、Dataphinプロジェクトにバインドすることができます。Dataphinプロジェクトは、プロジェクトメンバー、StarRocksストレージおよび計算スペースを管理し、計算タスクを管理および維持します。

Dataphinプロジェクトを作成するには、次の手順に従います。

1. システム管理者またはスーパー管理者としてDataphinにログインします。

2. プランニング > プロジェクト管理に移動します。

3. 右上隅の**Create project**をクリックしてプロジェクトを作成します。

4. 基本情報を入力し、以前のステップで作成したStarRocksエンジンをオフラインエンジンから選択します。

5. **Create**をクリックします。

##### StarRocks SQL

プロジェクトを作成した後、StarRocks SQLタスクを作成してStarRocks上でDDLまたはDML操作を実行できます。

詳細な手順は次のとおりです。

1. **R & D** > **Develop**に移動します。

2. 右上隅の'+'をクリックしてStarRocks SQLタスクを作成します。

   ![Dataphinプロジェクトの設定 - 1](../../assets/Dataphin/configure_dataphin_project_1.png)

3. 名前とスケジューリングタイプを入力してSQLタスクを作成します。

4. エディタにSQLを入力して、StarRocks上でDDLおよびDML操作を開始します。

   ![Dataphinプロジェクトの設定 - 2](../../assets/Dataphin/configure_dataphin_project_2.png)
