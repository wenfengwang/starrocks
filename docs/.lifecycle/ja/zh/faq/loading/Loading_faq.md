---
displayed_sidebar: Chinese
---

# インポートに関する一般的なFAQ

## 1. "close index channel failed" と "too many tablet versions" のエラーが発生した場合、どのように対処すればよいですか？

上記のエラーは、インポートの頻度が高すぎてデータがタイムリーにマージ（Compaction）されず、サポートされる最大未マージバージョン数を超えたために発生します。デフォルトでサポートされる最大未マージバージョン数は1000です。以下の方法でエラーを解決できます：

- インポートするデータ量を増やし、インポート頻度を下げる。

- BEの設定ファイル **be.conf** で以下の設定を変更し、マージ戦略を調整してマージを加速する目的を達成します：

    ```Plain
    cumulative_compaction_num_threads_per_disk = 4
    base_compaction_num_threads_per_disk = 2
    cumulative_compaction_check_interval_seconds = 2
    ```

  設定変更後は、メモリとI/Oを観察し、メモリとI/Oが正常であることを確認する必要があります。

## 2. "Label Already Exists" のエラーが発生した場合、どのように対処すればよいですか？

StarRocksクラスター内の同じデータベースに、既に同じラベルを持つインポートジョブが成功しているか、実行中です。原因は以下の通りです：

Stream LoadはHTTPプロトコルを使用してインポートジョブのリクエストを送信するため、一般的に各言語のHTTPクライアントにはリクエストのリトライロジックが組み込まれています。StarRocksクラスターが最初のリクエストを受け取った後、Stream Loadの操作を開始しますが、クライアントにタイムリーに結果を返さないため、クライアントが同じリクエストを再送信するリトライが発生することがあります。この場合、StarRocksクラスターは最初のリクエストを操作しているため、2番目のリクエストには `Label Already Exists` のステータスが返されます。

異なるインポート方法間でラベルの衝突がないか、または重複してインポートジョブが送信されていないかを確認する必要があります。調査方法は以下の通りです：

- ラベルを使用してメインFEのログを検索し、同じラベルが2回出現しているかどうかを確認します。もしそうなら、クライアントがリクエストを重複して送信したことを意味します。

  > **注記**
  >
  > StarRocksクラスター内のインポートジョブのラベルはインポート方法に関係なく共通です。したがって、異なるインポートジョブが同じラベルを使用している可能性があります。

- `SHOW LOAD WHERE LABEL = "xxx"` コマンドを実行し、ラベルが同じで **FINISHED** 状態のインポートジョブが既に存在するかどうかを確認します。

  > **注記**
  >
  > ここでの `xxx` は確認したいラベル文字列です。

現在のリクエストによるインポートのデータ量に基づいて、おおよそのインポート時間を計算し、インポートのタイムアウト時間に応じてクライアントのリクエストタイムアウト時間を適切に延長することをお勧めします。これにより、クライアントがリクエストを複数回送信するのを防ぐことができます。

## 3. データ品質エラー "ETL_QUALITY_UNSATISFIED; msg:quality not good enough to cancel" が発生した場合、どのように対処すればよいですか？

[SHOW LOAD](../../sql-reference/sql-statements/data-manipulation/SHOW_LOAD.md) コマンドを実行します。コマンドの結果で得られた情報からURLを見つけ、エラーデータを確認します。

一般的なデータ品質エラーには以下のようなものがあります：

- 「CSV文字列をINTに変換できませんでした。」
  
  ソースデータファイルのある列の文字列を対応する型のデータに変換する際にエラーが発生しました。例えば、`abc` を数値に変換する際に失敗しました。

- 「入力の長さがスキーマよりも長すぎます。」
  
  ソースデータファイルのある列の長さが正しくありません。例えば、固定長文字列がテーブル作成時に設定された長さを超えている、またはINT型のフィールドが4バイトを超えています。

- 「実際の列数がスキーマの列数より少ないです。」
  
  ソースデータファイルのある行を指定された区切り文字で分割した後、列数が指定された列数より少ないです。おそらく区切り文字が正しくないことが原因です。

- 「実際の列数がスキーマの列数を超えています。」
  
  ソースデータファイルのある行を指定された区切り文字で分割した後、列数が指定された列数を超えています。

- 「小数部分の長さがスキーマのスケールより長いです。」
  
  ソースデータファイルのあるDECIMAL型の列の小数部分が指定された長さを超えています。

- 「整数部分の長さがスキーマの精度より長いです。」
  
  ソースデータファイルのあるDECIMAL型の列の整数部分が指定された長さを超えています。

- 「このキーに対応するパーティションがありません。」
  
  ソースデータファイルのある行のパーティション列の値がパーティション範囲外です。

## 4. インポート中にRPCタイムアウトが発生した場合、どのように対処すればよいですか？

BEの設定ファイル **be.conf** で `write_buffer_size` パラメータの設定を確認します。このパラメータはBE上のメモリブロックのサイズ閾値を制御するために使用され、デフォルトの閾値は100MBです。閾値が大きすぎると、リモートプロシージャコール（Remote Procedure Call、RPC）のタイムアウトを引き起こす可能性があります。この場合、BEの設定ファイルの `tablet_writer_rpc_timeout_sec` パラメータと連携して `write_buffer_size` パラメータの値を適切に調整する必要があります。[BE設定](../../loading/Loading_intro.md#be-設定)を参照してください。

## 5. インポートジョブでエラー "Value count does not match column count" が発生した場合、どのように対処すればよいですか？

インポートジョブが失敗し、エラー詳細URLを確認すると "Value count does not match column count" エラーが返され、解析されたソースデータの列数がターゲットテーブルの列数と一致しないことを示しています：

```Java
Error: Value count does not match column count. Expect 3, but got 1. Row: 2023-01-01T18:29:00Z,cpu0,80.99
Error: Value count does not match column count. Expect 3, but got 1. Row: 2023-01-01T18:29:10Z,cpu1,75.23
Error: Value count does not match column count. Expect 3, but got 1. Row: 2023-01-01T18:29:20Z,cpu2,59.44
```

このエラーが発生した原因は、インポートコマンドまたはインポートステートメントで指定された列の区切り文字がソースデータの列の区切り文字と一致していないためです。例えば、上記の例ではソースデータはCSV形式で3列あり、列の区切り文字はコンマ(`,`)ですが、インポートコマンドまたはインポートステートメントではタブ(`\t`)を列の区切り文字として指定しているため、最終的にソースデータの3列が1列として解析されてしまいます。

インポートコマンドまたはインポートステートメントの列の区切り文字をコンマ(`,`)に変更し、再度インポートを試みてください。
