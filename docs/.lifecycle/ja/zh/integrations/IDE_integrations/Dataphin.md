---
displayed_sidebar: Chinese
---

# Dataphin

Dataphinは、阿里巴巴グループのOneDataデータガバナンス方法論のクラウド化された出力であり、データの収集、構築、管理、利用の全生命周期のビッグデータ能力を一元的に提供し、企業のデータガバナンスレベルを大幅に向上させ、品質の信頼性、消費の利便性、生産の安全性と経済性を備えた企業向けのデータミドルウェアを構築することを目指しています。Dataphinは、さまざまな計算プラットフォームのサポートと拡張可能なオープンな機能を提供し、さまざまな業界の企業のプラットフォーム技術アーキテクチャと特定の要求に対応しています。

Dataphinは、StarRocksとの統合を以下のシナリオで提供しています：

- StarRocksから他のデータソースにデータを読み込み、または他のデータソースからStarRocksにデータを書き込むためのデータ統合のソースまたはターゲットデータソースとしてのサポート。

- リアルタイム開発のソーステーブル、ディメンションテーブル、または結果テーブルとしてのサポート。

- データウェアハウスまたはデータマーケットとして、StarRocksをDataphinの計算ソースとして登録し、SQL開発およびスケジューリング、データ品質チェック、セキュリティ識別などのデータ開発およびガバナンス作業を実行することができます。

## データ統合

Dataphinでは、StarRocksデータソースを作成し、オフライン統合タスクでStarRocksデータソースをソースデータベースまたはターゲットデータベースとして使用することができます。具体的な手順は以下の通りです：

### StarRocksデータソースの作成

#### 基本情報

![StarRocksデータソースの作成 - 基本情報](../../assets/Dataphin/create_sr_datasource_1.png)

- **データソース名**: 必須。データソースの名前を入力します。名前には、漢字、英字、数字、アンダースコア（_）、ハイフン（-）のみを含めることができます。長さは64文字を超えることはできません。

- **データソースコード**: オプション。データソースコードを設定すると、Flink SQLタスクで`データソースコード.table`または`データソースコード.schema.table`の形式でデータソースのテーブルを参照することができます。環境に応じて対応する環境のデータソースに自動的にアクセスする場合は、`${データソースコード}.table`または`${データソースコード}.schema.table`の形式でアクセスしてください。注意：現在、MySQL、Hologres、MaxComputeデータソースのみをサポートしています。

- **サポートされるアプリケーションシナリオ**: StarRocksデータソースのサポートされるアプリケーションシナリオ。

- **データソースの説明**: オプション。データソースの簡単な説明を入力します。長さは128文字を超えることはできません。

- **データソースの設定**: 必須。ビジネスデータソースが本番データソースと開発データソースを区別する場合は、「本番+開発データソース」を選択します。ビジネスデータソースが本番データソースと開発データソースを区別しない場合は、「本番データソース」を選択します。

- **タグ**: オプション。データソースにタグを選択して分類します。

#### 設定情報

![StarRocksデータソースの作成 - 設定情報](../../assets/Dataphin/create_sr_datasource_2.png)

- **JDBC URL**: 必須。`jdbc:mysql://<host>:<port>/<dbname>`の形式で入力します。`host`はStarRocksクラスタのFE（Front End）ホストのIPアドレス、`port`はFEのクエリポート、`dbname`はデータベース名です。

- **Load URL**: 必須。`fe_ip:http_port;fe_ip:http_port`の形式で入力します。`fe_ip`はFEのホスト、`http_port`はFEのHTTPポートです。

- **ユーザー名**: 必須。データベースのユーザー名です。

- **パスワード**: 必須。データベースのパスワードです。

#### 高度な設定

![StarRocksデータソースの作成 - 高度な設定](../../assets/Dataphin/create_sr_datasource_3.png)

- **connectTimeout**: データベースの`connectTimeout`の長さ（単位：ミリ秒）、デフォルトは900000ミリ秒（15分）です。

- **socketTimeout**: データベースの`socketTimeout`の長さ（単位：ミリ秒）、デフォルトは1800000ミリ秒（30分）です。

### StarRocksデータソースから他のデータソースにデータを読み込む

#### オフライン統合タスクキャンバスにStarRocks入力コンポーネントをドラッグアンドドロップ

![StarRocksから読み込む - 1](../../assets/Dataphin/read_from_sr_datasource_1.png)

#### StarRocks入力コンポーネントの設定

![StarRocksから読み込む - 2](../../assets/Dataphin/read_from_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントの使用シナリオと位置に基づいて適切な名前を入力します。

- **データソース**: Dataphinで作成したStarRocksデータソースまたはプロジェクトを選択できます。データソースの同期読み取り権限を持つ設定者が必要です。条件を満たさない場合は、データソースの追加または関連する権限の申請ができます。

- **ソーステーブル情報**: 実際のシナリオに応じて、入力として単一のテーブルまたは同じテーブル構造を持つ複数のテーブルを選択します。

- **テーブル**: StarRocksデータソースから選択できるテーブルです。

- **分割キー**: 並列度の設定に使用します。ソースデータテーブルの特定の列を分割キーとして使用できます。このフィールドの型は整数型である必要があります。主キーまたはインデックスのある列を分割キーとして使用することをお勧めします。

- **バッチサイズ**: データをバッチで抽出するレコード数です。

- **フィルタ情報**: フィルタ情報は必須ではありません。

  次の2つの場合に関連情報を入力します：

  - 固定の一部のデータ。
  - パラメータフィルタリング。例えば、毎日の増分追加または全量カバレッジのデータを取得する場合、Dataphinのシステム時刻パラメータでテーブル内の日付フィールドを制限する場合があります。例えば、StarRocksライブラリの取引テーブル、トランザクション作成日=`${bizdate}`。

- **出力フィールド**: 選択したテーブルの情報に基づいて、テーブルのフィールドを出力フィールドとして取得します。フィールドの名前を変更したり、削除したり、追加したり、フィールドの順序を変更したりすることができます。一般的には、名前を変更することで下流のデータの可読性を向上させたり、出力時のフィールドのマッピングを容易にするためにフィールドを削除したりします。フィールドの順序を変更することは、複数の入力データをマージまたは出力する場合に、名前が一致しない場合に行単位のマッピングを使用して効率的にデータをマージまたはマッピング出力するためです。

### ターゲットデータソースを出力コンポーネントとして選択し、設定します

![データソースを出力コンポーネントとして選択](../../assets/Dataphin/write_to_sr_datasource_1.png)

#### ターゲットデータソースを出力コンポーネントとして選択し、出力コンポーネントを設定します

![StarRocksから読み込む - 3](../../assets/Dataphin/read_from_sr_datasource_3.png)

### 他のデータソースからStarRocksデータソースにデータを読み込む

#### オフライン統合タスクで入力コンポーネントを設定し、StarRocks出力コンポーネントを下流に設定します

![StarRocksに書き込む - 1](../../assets/Dataphin/write_to_sr_datasource_1.png)

#### StarRocks出力コンポーネントの設定

![StarRocksに書き込む - 2](../../assets/Dataphin/write_to_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントの使用シナリオと位置に基づいて適切な名前を入力します。

- **データソース**: Dataphinで作成したStarRocksデータソースまたはプロジェクトを選択できます。データソースの同期書き込み権限を持つ設定者が必要です。条件を満たさない場合は、データソースの追加または関連する権限の申請ができます。

- **テーブル**: StarRocksデータソースから選択できるテーブルで、データの書き込み先となります。

- **一括生成ターゲットテーブル**: StarRocksデータソースにまだターゲットテーブルが作成されていない場合、上流の読み取りフィールド名、タイプ、コメントを自動的に取得してテーブル作成ステートメントを生成し、このボタンをクリックすると一括生成できます。

- **CSVインポート列区切り記号**: CSV形式でStream Loadを使用してインポートする場合、CSVインポート列区切り記号を設定できます。デフォルトは`\t`ですが、デフォルト値を使用する場合は明示的に指定しないでください。データ自体に`\t`が含まれている場合は、区切り記号として他の文字を使用する必要があります。

- **CSVインポート行区切り記号**: CSV形式でStream Loadを使用してインポートする場合、CSVインポート行区切り記号を設定できます。デフォルトは`\n`ですが、デフォルト値を使用する場合は明示的に指定しないでください。データ自体に`\n`が含まれている場合は、区切り記号として他の文字を使用する必要があります。

- **解析プラン**: 必須ではありません。データの出力前および出力後の特殊な処理を指します。準備ステートメントは、データをStarRocksデータソースに書き込む前に実行され、終了ステートメントは書き込みが完了した後に実行されます。

- **フィールドマッピング**: 上流の入力とターゲットテーブルのフィールドに基づいて、フィールドマッピングを手動で選択するか、行または列のマッピングに基づいて一括で選択することができます。

## リアルタイム開発

### 概要

企業のリアルタイム計算シナリオで広く活用されています。リアルタイムビジネスモニタリングと分析、リアルタイムユーザー行動分析、リアルタイム広告入札システム、リアルタイムリスク管理と詐欺対策、およびリアルタイムモニタリングと警告などのアプリケーションシナリオに使用することができます。リアルタイムなデータ分析とクエリにより、企業は迅速にビジネス状況を把握し、意思決定を最適化し、より良いサービスを提供し、企業の利益を保護することができます。

### StarRocksコネクタ

Flinkのコネクタは、内部の結果テーブルをキャッシュし、Stream Loadを使用してバッチでインポートすることで実現されます。ソーステーブルは、バッチでデータを読み込むことで実現されます。StarRocksコネクタがサポートする情報は以下の通りです。

| **カテゴリ**                 | **詳細**             |
| ---------------------------- | -------------------- |
| サポートされるタイプ         | ソーステーブル、ディメンションテーブル、結果テーブル |
| 実行モード                   | ストリームモードとバッチモード       |
| データ形式                   | JSONとCSV            |
| 特有のモニタリングメトリック | なし                 |
| サポートされるAPIの種類      | DataStreamとSQL      |
| 結果テーブルのデータの更新または削除をサポートするか | はい                   |

### 使用方法

Dataphin は StarRocks データソースをリアルタイム計算の読み書き対象としてサポートし、StarRocks メタテーブルの作成とリアルタイム計算タスクでの使用をサポートしています。以下は操作手順の例です：

#### StarRocks メタテーブルの作成

1. **Dataphin** > **研究開発** > **開発** > **テーブル管理**に進む。

2. **新規作成**をクリックし、**リアルタイム計算テーブル**を選択。

   ![StarRocks メタテーブルの作成 - 1](../../assets/Dataphin/create_sr_metatable_1.png)

   - **テーブルタイプ**：**メタテーブル**を選択。

   - **メタテーブル名**：メタテーブルの名前を入力。

   - **データソース**：StarRocks タイプのデータソースを選択。

   - **ソーステーブル**：ソースとなる物理テーブルを選択。

   - **ディレクトリ選択**：新規テーブルのディレクトリを選択。

   - **説明**：任意。元のテーブルの簡単な説明を入力。

   ![StarRocks メタテーブルの作成 - 2](../../assets/Dataphin/create_sr_metatable_2.png)

3. メタテーブルを作成した後、データソース、ソーステーブル、メタテーブルのフィールド、メタテーブルパラメータの設定など、メタテーブルの編集が可能です。

   ![StarRocksメタテーブルの編集](../../assets/Dataphin/edit_sr_metatable_1.png)

4. メタテーブルをサブミットします。

#### Kafka のデータをリアルタイムに StarRocks に書き込むための Flink SQL タスクの作成

1. **Dataphin** > **研究開発** > **開発** > **計算タスク**に進む。

2. **新規 Flink SQL タスク**をクリック。

   ![Flink SQL タスクの作成 -1 ](../../assets/Dataphin/create_flink_task_1.png)

3. Fink SQL コードを編集し、プリコンパイルを行います。ここでは Kafka メタテーブルを入力テーブルとして、StarRocks メタテーブルを出力テーブルとして使用します。

   ![Flink SQL タスクの作成 - 2](../../assets/Dataphin/create_flink_task_2.png)

   ![Flink SQL タスクの作成 - 3](../../assets/Dataphin/create_flink_task_3.png)

4. プリコンパイルが成功したら、コードのデバッグやサブミットが可能です。

5. 開発環境でテストを行い、ログ出力やテストテーブルの書き込みの2つの方法でテストが可能です。テストテーブルは**メタテーブル** > **属性** > **デバッグテスト設定**で設定できます。

   ![Flink SQL タスクの作成 - 4](../../assets/Dataphin/create_flink_task_4.png)

   ![Flink SQL タスクの作成 - 5](../../assets/Dataphin/create_flink_task_5.png)

6. 開発環境でタスクが正常に動作した後、使用したメタテーブルと一緒に本番環境にリリースすることができます。

   ![Flink SQL タスクの作成 - 6](../../assets/Dataphin/create_flink_task_6.png)

7. 本番環境でタスクを起動し、Kafka のデータをリアルタイムに StarRocks に書き込みます。実行分析で各指標の状況やログを確認してタスクの実行状況を把握したり、タスクにモニタリングアラートを設定することができます。

## データウェアハウスまたはデータマート

### 前提条件

- StarRocks のバージョンは 3.0.6 以上であること。

- Dataphin がインストールされており、そのバージョンは 3.12 以上であること。

- 統計情報の収集が有効になっており、StarRocks のインストール後にデフォルトで有効になっています。詳細は[CBO 統計情報](https://docs.starrocks.io/zh-cn/latest/using_starrocks/Cost_based_optimizer)を参照してください。

- StarRocks Internal Catalog のみをサポートし、`default_catalog`として、External Catalog はサポートしていません。

### 接続設定説明

#### メタデータストアの設定

Dataphin はメタデータに基づいて情報を表示および提示することができ、テーブルの使用情報やメタデータの変更などを含みます。StarRocks を使用してメタデータの処理計算をサポートしています。そのため、使用を開始する前に、メタデータ計算エンジン（メタデータストア）の初期設定が必要です。設定手順は以下の通りです：

1. 管理者として Dataphin メタデータストアテナントにログインします。

2. **管理センター** > **システム設定** > **メタデータストア設定**に進む。

   a. **開始**をクリック。

   b. **StarRocks**を選択。

   c. パラメータを設定し、接続テストを通過した後、**次へ**をクリック。

   d. メタデータストアの初期化を完了します。

   ![メタデータ計算エンジンの設定](../../assets/Dataphin/metadata_engine_settings_1.png)

   パラメータの説明は以下の通りです：

   - **JDBC URL**：JDBC 接続文字列は、MySQL JDBC URL 形式 `https://dev.mysql.com/doc/connector-j/8.1/en/connector-j-reference-jdbc-url-format.html`を参考に、2つの部分に分けて記入します。

     - 第一部分：形式は `jdbc:mysql://<Host>:<Port>/`で、`Host`は StarRocks クラスタの FE ホスト IP アドレス、`Port`は FE のクエリポートで、デフォルトは 9030 です。

     - 第二部分：形式は `database?key1=value1&key2=value2`で、`database`はメタデータ計算に使用する StarRocks のデータベース名で、必須項目です。`?`以降のパラメータは任意です。

   - **Load URL**：形式は `fe_ip:http_port;fe_ip:http_port`で、`fe_ip`は FE のホスト、`http_port`は FE の HTTP ポートです。

   - **ユーザー名**：StarRocks への接続ユーザー名。

     このユーザーは JDBC URL で指定されたデータベースに対する読み書き権限が必要で、以下のデータベースおよびテーブルへのアクセス権が必要です：

     - Information Schema のすべてのテーブル

     - _statistics_.column_statistics

     - _statistics_.table_statistic_v1

   - **パスワード**：StarRocks への接続パスワード。

   - **Meta Project**：Dataphin がメタデータ処理に使用するプロジェクト名で、Dataphin システム内部でのみ使用されます。**dataphin_meta**の使用を推奨します。

#### StarRocks プロジェクトの作成とデータ開発の開始

データ開発を開始するには、以下の手順が含まれます：

1. 計算設定。

2. StarRocks 計算ソースの作成。

3. Dataphin プロジェクトの作成。

4. StarRocks SQL タスクの作成。

##### ステップ1：計算設定

計算設定では、テナント内の計算エンジンタイプとクラスタのアドレスが設定されます。詳細な手順は以下の通りです：

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. **管理センター** > **システム設定** > **計算設定**に進む。

3. **StarRocks**を選択し、**次へ**をクリック。

4. **JDBC URL**を記入し、検証が完了するのを待ちます。JDBC URL の形式は `jdbc:mysql://<Host>:<Port>/`で、`Host`は StarRocks クラスタの FE ホスト IP アドレス、`Port`は FE のクエリポートで、デフォルトは 9030 です。

##### ステップ2：StarRocks 計算ソースの作成

計算ソースは Dataphin の概念で、Dataphin のプロジェクトスペースを StarRocks のストレージ計算スペース（つまりデータベース）にバインドおよび登録することが主な目的です。各プロジェクトに対して計算ソースを作成する必要があります。詳細な手順は以下の通りです：

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. **計画** > **計算ソース**に進む。

3. 右上の**新規計算ソース**をクリックして計算ソースを作成します。

   詳細な設定情報は以下の通りです：

   **基本情報**

   ![コンピューティング エンジンの作成 - 1](../../assets/Dataphin/create_compute_engine_1.png)

   - **計算ソースタイプ**：**StarRocks**を選択。

   - **計算ソース名**：作成するプロジェクト名と一致させることをお勧めします。開発プロジェクトの場合は、**_dev**のサフィックスを追加します。

   - **計算ソース説明**：任意。計算ソースの説明を入力します。

   **設定情報**

   ![コンピューティング エンジンの作成 - 2](../../assets/Dataphin/create_compute_engine_2.png)

   - **JDBC URL**：形式は `jdbc:mysql://<Host>:<Port>/`で、`Host`は StarRocks クラスタの FE ホスト IP アドレス、`Port`は FE のクエリポートで、デフォルトは 9030 です。

   - **Load URL**：形式は `fe_ip:http_port;fe_ip:http_port`で、`fe_ip`は FE のホスト、`http_port`は FE の HTTP ポートです。

   - **ユーザー名**：StarRocks への接続ユーザー名。

   - **パスワード**：StarRocks への接続パスワード。

   - **タスクリソースグループ**：異なる優先度のタスクに対して異なる StarRocks リソースグループを指定できます。**リソースグループを指定しない**を選択した場合、実行するリソースグループは StarRocks エンジンによって決定されます。**リソースグループを指定**を選択した場合、異なる優先度のタスクは実行時に Dataphin によって設定されたリソースグループに指定されます。SQL タスクのコード内や論理テーブルの物化設定内でリソースグループが指定されている場合、その設定と物化設定が優先され、計算ソースのタスクリソースグループ設定はそのタスクの実行時には無視されます。

   ![コンピューティング エンジンの作成 - 3](../../assets/Dataphin/create_compute_engine_3.png)

##### ステップ3：Dataphin プロジェクトの作成

計算ソースを作成した後、Dataphin のプロジェクトにバインドできます。Dataphin のプロジェクトは、プロジェクトメンバーの管理、StarRocks のストレージおよび計算スペース、および計算タスクの管理と運用を担います。

Dataphin プロジェクトを作成する詳細な手順は以下の通りです：

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. **計画** > **プロジェクト**に進む。

3. 右上の**新規プロジェクト**をクリックしてプロジェクトを作成します。

4. 基本情報を入力し、オフライン計算ソースで前のステップで作成した StarRocks 計算ソースを選択します。

5. **作成完了**をクリックします。

##### ステップ4：StarRocks SQL タスクの作成

プロジェクトを作成した後、StarRocks SQL タスクを作成して StarRocks で DDL または DML 操作を開始することができます。

詳細な手順は以下の通りです：

1. **研究** > **開発**に進みます。

2. 右上隅の **+** をクリックして、StarRocks SQL タスクを作成します。

   ![Dataphin プロジェクトの作成 - 1](../../assets/Dataphin/configure_dataphin_project_1.png)

3. 名前とスケジュールタイプを入力して、SQL タスクの作成を完了します。

4. エディタに SQL を入力して、StarRocks で DDL および DML 操作を開始します。

   ![Dataphin プロジェクトの作成 - 2](../../assets/Dataphin/configure_dataphin_project_2.png)
