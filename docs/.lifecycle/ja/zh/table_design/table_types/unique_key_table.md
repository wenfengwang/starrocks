---
displayed_sidebar: Chinese
---

# 更新モデル

テーブル作成時には、プライマリキーと指標列を定義することができ、クエリ時には同じプライマリキーを持つデータグループの中から最新のデータを返します。詳細モデルに比べて、更新モデルはデータのインポートプロセスを簡略化し、リアルタイムで頻繁に更新されるシナリオをより良くサポートします。

## 適用シナリオ

リアルタイムで頻繁に更新されるビジネスシナリオ、例えば電子商取引の注文分析です。電子商取引のシナリオでは、注文の状態が頻繁に変わり、毎日の注文更新量は数億を超えることがあります。

## 原理

更新モデルは、集約モデルの特別なケースと見なすことができ、指標列で指定された集約関数は REPLACE で、同じプライマリキーを持つデータグループの中から最新のデータを返します。

データはバッチで複数回にわたって更新モデルにインポートされ、各バッチにはバージョン番号が割り当てられるため、同じプライマリキーのデータには複数のバージョンが存在する可能性があります。クエリ時には最新のバージョン（つまり最大のバージョン番号）のデータが返されます。詳細モデルと比較して、更新モデルはインポートプロセスを簡略化することで、リアルタイムで頻繁に更新されるデータをより良くサポートします。

例えば、以下の表では、`ID` がプライマリキーで、`value` が指標列で、`_version` は StarRocks の内部バージョン番号です。ここで、`ID` が 1 のデータには2つのインポートバッチがあり、バージョン番号はそれぞれ `1` と `2` です。`ID` が `2` のデータには3つのインポートバッチがあり、バージョン番号は `3`、`4`、`5` です。

| ID   | value | _version |
| ---- | ----- | -------- |
| 1    | 100   | 1        |
| 1    | 101   | 2        |
| 2    | 100   | 3        |
| 2    | 101   | 4        |
| 2    | 102   | 5        |

`ID` が `1` のデータをクエリすると、最新バージョンの `2` のデータのみが返され、`ID` が `2` のデータをクエリすると、最新バージョンの `5` のデータのみが返されます。最終的なクエリ結果は以下の通りです：

| ID   | value |
| ---- | ----- |
| 1    | 101   |
| 2    | 102   |

## テーブル作成

電子商取引の注文分析シナリオでは、注文の状態を日付ごとに統計分析することがよくあります。そのため、よく使用されるフィルタリングフィールドである注文作成時間 `create_time`、注文ID `order_id` をプライマリキーとし、他の列である注文状態 `order_state` と注文総額 `total_price` を指標列として設定します。これにより、リアルタイムで注文状態を更新する要求を満たすと同時に、クエリ時に迅速なフィルタリングが可能になります。

このビジネスシナリオでのテーブル作成ステートメントは以下の通りです：

```SQL
CREATE TABLE IF NOT EXISTS orders (
    create_time DATE NOT NULL COMMENT "create time of an order",
    order_id BIGINT NOT NULL COMMENT "id of an order",
    order_state INT COMMENT "state of an order",
    total_price BIGINT COMMENT "price of an order"
)
UNIQUE KEY(create_time, order_id)
DISTRIBUTED BY HASH(order_id)
PROPERTIES (
"replication_num" = "3"
); 
```

> **注意**
>
> - テーブル作成時には `DISTRIBUTED BY HASH` 句を使用してバケットキーを指定する必要があります。バケットキーの詳細については、[バケット分割](../Data_distribution.md#分桶)を参照してください。
> - 2.5.7 バージョンから、StarRocks はテーブル作成とパーティション追加時に自動的にバケット数 (BUCKETS) を設定することをサポートしており、手動でバケット数を設定する必要はありません。詳細は、[バケット数の決定](../Data_distribution.md#确定分桶数量)を参照してください。

## 使用説明

- プライマリキーに関する説明：
  - テーブル作成ステートメントでは、プライマリキーは他の列の前に定義する必要があります。
  - プライマリキーは `UNIQUE KEY` で定義されます。
  - プライマリキーは一意性の制約を満たす必要があり、列の値は変更されません。
  - 合理的なプライマリキーを設定します。
    - クエリ時には、プライマリキーを使用して集約前にフィルタリングが可能で、指標列のフィルタリングは通常、複数バージョンの集約後に行われるため、頻繁に使用されるフィルタリングフィールドをプライマリキーとして設定することで、クエリのパフォーマンスを向上させることが推奨されます。
    - 集約プロセスではすべてのプライマリキーが比較されるため、過剰なプライマリキーの設定は避け、クエリパフォーマンスの低下を防ぐ必要があります。クエリでフィルタ条件としてたまにしか使用されない列は、プライマリキーに含めないことを推奨します。

- テーブル作成時には、指標列に BITMAP や Bloom Filter などのインデックスを作成することはできません。

## 次のステップ

テーブル作成が完了したら、さまざまなインポートジョブを作成してデータをテーブルにインポートできます。具体的なインポート方法については、[インポート概要](../../loading/Loading_intro.md)を参照してください。

> - データのインポート時には、全列の更新のみがサポートされており、インポートタスクではすべての列を明示する必要があります。例えば、`create_time`、`order_id`、`order_state`、`total_price` の4つの列です。
>
> - インポート頻度の設計では、ビジネスが要求するリアルタイム性を満たすことを基準にすることを推奨します。更新モデルのデータをクエリする際には、複数バージョンのデータを集約する必要があり、バージョンが多すぎるとクエリパフォーマンスが低下する可能性があります。そのため、更新モデルへのデータインポート時には、インポート頻度を適切に下げてクエリパフォーマンスを向上させることが重要です。ビジネスが要求するリアルタイム性が分単位であれば、1分ごとに更新データをインポートするだけで十分であり、秒単位でのインポートは必要ありません。
