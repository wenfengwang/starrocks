---
displayed_sidebar: Chinese
---

# SHOW LOAD

## 機能

指定されたインポートジョブに関する情報をデータベースで表示します。これには [Broker Load](../data-manipulation/BROKER_LOAD.md)、[INSERT](./INSERT.md)、[Spark Load](../data-manipulation/SPARK_LOAD.md) が含まれます。また、`curl` コマンドを使用してこれらのインポートジョブに関する情報を表示することもできます。注意：バージョン 3.1 以降、Broker Load および Insert インポートについては、`information_schema` データベースの [`loads`](../../../reference/information_schema/loads.md) テーブルから [SELECT](../data-manipulation/SELECT.md) ステートメントを使用してジョブ結果を表示することを推奨します。詳細は [HDFS からのインポート](../../../loading/hdfs_load.md)、[クラウドストレージからのインポート](../../../loading/cloud_storage_load.md)、[INSERT ステートメントを使用したデータのインポート](../../../loading/InsertInto.md)、[Apache Spark™ を使用したバルクインポート](../../../loading/SparkLoad.md) を参照してください。

上記の三つのインポート方法に加えて、StarRocks は Stream Load と Routine Load もサポートしています。Stream Load は同期操作で、結果が直接返されるため、SHOW LOAD では表示されません。Routine Load は [SHOW ROUTINE LOAD](../data-manipulation/SHOW_ROUTINE_LOAD.md) を使用してインポートジョブに関する情報を表示できます。

## 文法

```SQL
SHOW LOAD [ FROM db_name ]
[
   WHERE [ LABEL { = "label_name" | LIKE "label_matcher" } ]
         [ [AND] STATE = { "PENDING" | "ETL" | "LOADING" | "FINISHED" | "CANCELLED" } ]
]
[ ORDER BY field_name [ ASC | DESC ] ]
[ LIMIT { [offset, ] limit | limit OFFSET offset } ]
```

> **説明**
>
> 結果に多くのフィールドが含まれるため、`\G` を使用して行を分割することができます。例：`SHOW LOAD WHERE LABEL = "label1"\G;` 詳細は[例一](#例)を参照してください。

## パラメータ説明

| **パラメータ**                     | **必須** | **説明**                                                     |
| --------------------------------- | -------- | ------------------------------------------------------------ |
| db_name                           | いいえ       | データベース名。指定しない場合は、現在のデータベースのインポートジョブが表示されます。 |
| LABEL = "label_name"              | いいえ       | インポートジョブのラベル。                                               |
| LABEL LIKE "label_matcher"        | いいえ       | `label_matcher` を含むラベルのインポートジョブを表示します。                  |
| AND                               | いいえ       | <ul><li>一つのフィルタ条件のみを使用する場合は、このキーワードを指定する必要はありません。例：`WHERE STATE = "PENDING"`。</li><li>二つまたは三つのフィルタ条件を使用する場合は、このキーワードを指定する必要があります。例：`WHERE LABEL = "label_name" AND STATE = "PENDING"`。</li></ul> |
| STATE                             | いいえ       | インポートジョブの状態。インポート方法によって異なる状態があります。詳細は以下の通りです：<ul><li>Broker Load<ul><li>`PENDING`：インポートジョブが作成されました。</li><li>`QUEUEING`：インポートジョブが実行待ちです。</li><li>`LOADING`：インポートジョブが実行中です。</li><li>`PREPARED`：トランザクションがコミットされました。</li><li>`FINISHED`：インポートジョブが成功しました。</li><li>`CANCELLED`：インポートジョブが失敗しました。</li></ul></li><li>Spark Load<ul><li>`PENDING`：ETL タスクの設定を準備し、Apache Spark™ クラスターに ETL タスクを送信します。</li><li>`ETL`：Spark クラスターが ETL タスクを実行し、結果を Spark の HDFS に書き込みます。</li><li>`LOADING`：HDFS のソースデータを StarRocks のターゲットテーブルにインポートしています。</li><li>`PREPARED`：トランザクションがコミットされました。</li><li>`FINISHED`：インポートジョブが成功しました。</li><li>`CANCELLED`：インポートジョブが失敗しました。</li></ul></li><li>INSERT<ul><li>`FINISHED`：インポートジョブが成功しました。</li><li>`CANCELLED`：インポートジョブが失敗しました。</li></ul></li></ul>指定しない場合は、すべての状態のインポートジョブが表示されます。指定すると、指定された状態のインポートジョブのみが表示されます。例：`STATE = "PENDING"` は `PENDING` 状態のインポートジョブを表示します。|
| ORDER BY field_name [ASC \| DESC] | いいえ       | 結果を指定されたフィールドで昇順または降順に並べ替えます。現在サポートされている並べ替えフィールド（field_name）には `JobId`、`Label`、`State`、`Progress`、`Type`、`EtlInfo`、`TaskInfo`、`ErrorMsg`、`CreateTime`、`EtlStartTime`、`EtlFinishTime`、`LoadStartTime`、`LoadFinishTime`、`URL`、`JobDetails` があります。<ul><li>昇順に並べるには `ORDER BY field_name ASC` を指定します。</li><li>降順に並べるには `ORDER BY field_name DESC` を指定します。</li></ul>並べ替えフィールドと並べ替え順序の両方を指定しない場合は、デフォルトで `JobId` による昇順になります。 |
| LIMIT { [offset, ] limit | limit OFFSET offset } | いいえ       | 表示するジョブの数を指定します。指定しない場合は、フィルタ条件に一致するすべてのジョブが表示されます。指定すると、指定された数のジョブが表示されます。例：`LIMIT 10` はフィルタ条件に一致する最初の10ジョブを表示します。 |
| OFFSET offset                     | いいえ       | `offset` は結果からスキップされるインポートジョブの数を定義します。デフォルトは 0 です。例：`OFFSET 5` は最初の5つのインポートジョブをスキップし、残りの結果を返します。 |

## 結果説明

```plain
+-------+-------+-------+----------+------+---------+----------+----------+------------+--------------+---------------+---------------+----------------+-----+------------+
| JobId | Label | State | Progress | Type | Priority | EtlInfo | TaskInfo | ErrorMsg | CreateTime | EtlStartTime | EtlFinishTime | LoadStartTime | LoadFinishTime | URL | JobDetails |
+-------+-------+-------+----------+------+---------+----------+----------+------------+--------------+---------------+---------------+----------------+-----+------------+
```

インポート方法によって、結果のフィールド値が異なります。詳細は以下の通りです。

| **フィールド** | **Broker Load**                                              | **Spark Load**                                               | **INSERT**                                                   |
| -------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| JobId          | インポートジョブのグローバル一意 ID。StarRocks によって自動生成されます。 | Broker Load と同じ。                                        | Broker Load と同じ。                                        |
| Label          | インポートジョブのラベル。各データベース内のインポートジョブは一意のラベルを持ちますが、異なるデータベース間ではラベルが重複することがあります。 | Broker Load と同じ。                                        | Broker Load と同じ。                                        |
| State          | インポートジョブの状態。以下を含みます：<ul><li>`PENDING`：インポートジョブが作成されました。</li><li>`QUEUEING`：インポートジョブが実行待ちです。</li><li>`LOADING`：インポートジョブが実行中です。</li><li>`PREPARED`：トランザクションがコミットされました。</li><li>`FINISHED`：インポートジョブが成功しました。</li><li>`CANCELLED`：インポートジョブが失敗しました。</li></ul> | インポートジョブの状態。以下を含みます：<ul><li>`PENDING`：ETL タスクの設定を準備し、Spark クラスターに ETL タスクを送信します。</li><li>`ETL`：Spark クラスターが ETL タスクを実行し、結果を Spark の HDFS に書き込みます。</li><li>`LOADING`：HDFS のソースデータを StarRocks のターゲットテーブルにインポートしています。</li><li>`PREPARED`：トランザクションがコミットされました。</li><li>`FINISHED`：インポートジョブが成功しました。</li><li>`CANCELLED`：インポートジョブが失敗しました。</li></ul> | インポートジョブの状態。以下を含みます：<ul><li>`FINISHED`：インポートジョブが成功しました。</li><li>`CANCELLED`：インポートジョブが失敗しました。</li></ul> |
| Progress       | インポートジョブの進行状況。Broker Load は `LOAD` のみの段階で、`LOADING` 状態に対応します。進行状況は 0~100% です。Broker Load には `ETL` の段階がないため、`ETL` の値は意味を持ちません。<br />**説明**：<ul><li>`LOAD` の進行状況は、完了したデータインポートのターゲットテーブル数 / インポートジョブでデータインポートを行うターゲットテーブルの総数 * 100% で計算されます。</li><li>すべてのターゲットテーブルにデータがインポートされると、`LOAD` の進行状況は 99% と表示され、この時点でインポートは最終的な有効化段階に入ります。インポートプロセス全体が完了すると、`LOAD` の進行状況は 100% と表示されます。</li><li>インポートの進行状況は線形ではありません。進行状況がしばらく変わらない場合でも、インポートが続行されていないわけではありません。</li></ul> | インポートジョブの進行状況。Spark Load は `ETL` と `LOAD` の二つの段階があり、それぞれ `ETL` と `LOADING` 状態に対応します。`ETL` と `LOAD` の進行状況は共に 0~100% です。<br />**説明**：Broker Load と同じ。 | インポートジョブの進行状況。INSERT は `LOAD` のみの段階で、`ETL` の段階はありません。そのため、`ETL` の値は意味を持ちません。進行状況は 0~100% です。<br />**説明**：Broker Load と同じ。 |
| Type           | インポート方法。`BROKER` と表示されます。                     | インポート方法。`SPARK` と表示されます。                   | インポート方法。`INSERT` と表示されます。                   |
| Priority       | インポートジョブの優先度。`LOWEST`、`LOW`、`NORMAL`、`HIGH`、`HIGHEST` を含みます。 | -                                                            | -                                                            |

| EtlInfo        | ETL情報には以下の3つの指標が含まれます：<ul><li>`unselected.rows`：WHERE句で指定された条件によってフィルタリングされた行数。</li><li>`dpp.abnorm.ALL`：データ品質が不適合でフィルタリングされた行数。データ品質が不適合とは、ソーステーブルのデータ型や列数などがターゲットテーブルと一致しないデータ行のことです。</li><li>`dpp.norm.ALL`：実際にインポートされた行数。</li></ul>これら3つの指標の合計がデータソースの総行数です。これらの指標を基に、現在のインポートジョブのデータ品質不適合率が`max-filter-ratio`を超えているかどうかを計算できます。計算式は：`dpp.abnorm.ALL`/(`unselected.rows` + `dpp.abnorm.ALL` + `dpp.norm.ALL`)です。 | 同 Broker Load。                                             | ETL情報。INSERTにはETLフェーズがないため、このパラメータの値は`NULL`です。  |
| TaskInfo       | インポートジョブ作成時に指定されたパラメータには以下が含まれます：<ul><li>`resource`：このパラメータはBroker Loadのインポートジョブでは意味をなしません。</li><li>`timeout`：インポートジョブのタイムアウト時間。単位は秒。</li><li>`max-filter-ratio`：インポートジョブの最大許容フィルタリング比率、つまりデータが規格に合わないなどの理由でフィルタリングされたデータ行が占める最大比率。</li></ul>上記のパラメータの詳細については、[BROKER LOAD](../data-manipulation/BROKER_LOAD.md)を参照してください。 | インポートジョブ作成時に指定されたパラメータには以下が含まれます：<ul><li>`resource`：リソース名。</li><li>`timeout`：インポートジョブのタイムアウト時間。単位は秒。</li><li>`max-filter-ratio`：インポートジョブの最大許容フィルタリング比率、つまりデータが規格に合わないなどの理由でフィルタリングされたデータ行が占める最大比率。</li></ul>上記のパラメータの詳細については、[SPARK LOAD](../data-manipulation/SPARK_LOAD.md)を参照してください。 | インポートジョブ作成時に指定されたパラメータには以下が含まれます：<ul><li>`resource`：このパラメータはINSERTのインポートジョブでは意味をなしません。</li><li>`timeout`：インポートジョブのタイムアウト時間。単位は秒。</li><li>`max-filter-ratio`：このパラメータはINSERTのインポートジョブでは意味をなしません。</li></ul>詳細については、[INSERT](./INSERT.md)を参照してください。 |
| ErrorMsg       | インポートジョブの失敗原因。インポートジョブのステータスが`PENDING`、`LOADING`、または`FINISHED`の場合、このパラメータの値は`NULL`です。インポートジョブのステータスが`CANCELLED`の場合、このパラメータの値には`type`と`msg`の2部分が含まれます：<ul><li>`type`には以下の値が含まれます：<ul><li>`USER_CANCEL`：インポートジョブが手動でキャンセルされました。</li><li>`ETL_SUBMIT_FAIL`：インポートタスクの提出に失敗しました。</li><li>`ETL_QUALITY_UNSATISFIED`：データ品質が不適合で、インポートジョブのエラーデータ率が`max-filter-ratio`を超えました。</li><li>`LOAD_RUN_FAIL`：`LOAD`フェーズでインポートジョブが失敗しました。</li><li>`TIMEOUT`：インポートジョブが許可されたタイムアウト時間内に完了しませんでした。</li><li>`UNKNOWN`：未知のインポートエラーです。</li></ul></li><li>`msg`は失敗原因の詳細情報を表示します。</li></ul> | インポートジョブの失敗原因。インポートジョブのステータスが`PENDING`、`ETL`、`LOADING`、または`FINISHED`の場合、このパラメータの値は`NULL`です。インポートジョブのステータスが`CANCELLED`の場合、このパラメータの値には`type`と`msg`の2部分が含まれます：<ul><li>`type`には以下の値が含まれます：<ul><li>`USER_CANCEL`：インポートジョブが手動でキャンセルされました。</li><li>`ETL_SUBMIT_FAIL`：ETLの提出に失敗しました。</li><li>`ETL_RUN_FAIL`：ETLが実行に失敗しました。</li><li>`ETL_QUALITY_UNSATISFIED`：データ品質が不適合で、インポートジョブのエラーデータ率が`max-filter-ratio`を超えました。</li><li>`LOAD_RUN_FAIL`：`LOAD`フェーズでインポートジョブが失敗しました。</li><li>`TIMEOUT`：インポートジョブが許可されたタイムアウト時間内に完了しませんでした。</li><li>`UNKNOWN`：未知のインポートエラーです。</li></ul></li><li>`msg`は失敗原因の詳細情報を表示します。</li></ul> | インポートジョブの失敗原因。インポートジョブのステータスが`FINISHED`の場合、このパラメータの値は`NULL`です。インポートジョブのステータスが`CANCELLED`の場合、このパラメータの値には`type`と`msg`の2部分が含まれます：<ul><li>`type`には以下の値が含まれます：<ul><li>`USER_CANCEL`：インポートジョブが手動でキャンセルされました。</li><li>`ETL_SUBMIT_FAIL`：インポートジョブの提出に失敗しました。</li><li>`ETL_RUN_FAIL`：インポートジョブが実行に失敗しました。</li><li>`ETL_QUALITY_UNSATISFIED`：データ品質が不適合でインポートジョブが失敗しました。</li><li>`LOAD_RUN_FAIL`：`LOAD`フェーズでインポートジョブが失敗しました。</li><li>`TIMEOUT`：インポートジョブが許可されたタイムアウト時間内に完了しませんでした。</li><li>`UNKNOWN`：未知のインポートエラーです。</li><li>`TXN_UNKNOWN`：トランザクションの状態が不明でインポートジョブが失敗しました。</li></ul></li><li>`msg`は失敗原因の詳細情報を表示します。</li></ul> |
| CreateTime     | インポートジョブの作成時間。                                         | 同 Broker Load。                                             | 同 Broker Load。                                             |
| EtlStartTime   | Broker LoadのインポートにはETLフェーズがないため、このパラメータの値は`LoadStartTime`と同じです。 | ETLフェーズの開始時間。                                        | INSERTのインポートにはETLフェーズがないため、このパラメータの値は`LoadStartTime`と同じです。 |
| EtlFinishTime  | Broker LoadのインポートにはETLフェーズがないため、このパラメータの値は`LoadStartTime`と同じです。 | ETLフェーズの終了時間。                                        | INSERTのインポートにはETLフェーズがないため、このパラメータの値は`LoadStartTime`と同じです。 |
| LoadStartTime  | `LOAD`フェーズの開始時間。                                       | 同 Broker Load。                                             | 同 Broker Load。                                             |
| LoadFinishTime | インポートジョブの完了時間。                                         | 同 Broker Load。                                             | 同 Broker Load。                                             |
| URL            | インポートジョブで品質が不適合なデータのアクセスURL。`curl`または`wget`コマンドを使用してこのアドレスを開くことができます。インポートジョブに品質が不適合なデータが存在しない場合、このパラメータの値は`NULL`です。 | 同 Broker Load。                                             | 同 Broker Load。                                             |
| JobDetails     | インポートジョブのその他の情報には以下が含まれます：<ul><li>`Unfinished backends`：インポートが未完了のBEノードID。</li><li>`ScannedRows`：実際に処理された行数、インポートされた行数およびフィルタリングされた行数を含みます。</li><li>`TaskNumber`：サブジョブの数。</li><li>`All backends`：サブジョブを実行中のBEノードのID。</li><li>`FileNumber`：ソースファイルの数。</li><li>`FileSize`：すべてのソースファイルの合計データ量、単位はバイト。</li></ul> | 同 Broker Load。                                             | 同 Broker Load。                                             |

## 注意事項

- インポートジョブに関連する情報は時限性があります。デフォルトでは、インポートジョブの完了時間(`LoadFinishTime`)から3日以内に関連情報を確認できます。3日後には情報が失効し、確認できなくなります。FEのパラメータ`label_keep_max_second`を変更してデフォルトの有効期間（秒単位）を変更することができます。操作は以下の通りです：

    ```SQL
    ADMIN SET FRONTEND CONFIG ("label_keep_max_second" = "value");
    ```

- インポートジョブの`LoadStartTime`が長時間`N/A`のままである場合、インポートジョブの蓄積が深刻であることを意味します。ジョブの作成頻度を下げることができます。
- インポートジョブが消費する総時間 = `LoadFinishTime` - `CreateTime`。
- `LOAD`フェーズが消費する時間 = `LoadFinishTime` - `LoadStartTime`。

## 例

例1：現在のデータベース内のすべてのインポートジョブを確認します。

```plain
SHOW LOAD\G;
*************************** 1. row ***************************
         JobId: 976331
         Label: duplicate_table_with_null
         State: FINISHED
      Progress: ETL:100%; LOAD:100%
          Type: BROKER
      Priority: NORMAL 
       EtlInfo: unselected.rows=0; dpp.abnorm.ALL=0; dpp.norm.ALL=65546
      TaskInfo: resource:N/A; timeout(s):300; max_filter_ratio:0.0
      ErrorMsg: NULL
    CreateTime: 2022-10-17 19:35:00
  EtlStartTime: 2022-10-17 19:35:04
 EtlFinishTime: 2022-10-17 19:35:04
 LoadStartTime: 2022-10-17 19:35:04
LoadFinishTime: 2022-10-17 19:35:06
           URL: NULL
    JobDetails: {"Unfinished backends":{"b90a703c-6e5a-4fcb-a8e1-94eca5be0b8f":[]},"ScannedRows":65546,"TaskNumber":1,"All backends":{"b90a703c-6e5a-4fcb-a8e1-94eca5be0b8f":[10004]},"FileNumber":1,"FileSize":548622}
```


示例二：現在のデータベースのインポートジョブを確認します。インポートジョブのラベルには `null` という文字列が含まれている必要があり、2つのジョブのみを表示します。

```plain
SHOW LOAD 
WHERE LABEL LIKE "null" 
LIMIT 2;

+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| JobId | Label                     | State    | Progress            | Type   | EtlInfo                                                 | TaskInfo                                                                                                | ErrorMsg | CreateTime          | EtlStartTime        | EtlFinishTime       | LoadStartTime       | LoadFinishTime      | URL                                                                            | JobDetails                                                                                                                                                                                              |
+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 10082 | duplicate_table_with_null | FINISHED | ETL:100%; LOAD:100% | BROKER | unselected.rows=0; dpp.abnorm.ALL=0; dpp.norm.ALL=65546 | resource:N/A; timeout(s):300; max_filter_ratio:0.0                                                      | NULL     | 2022-08-02 14:53:27 | 2022-08-02 14:53:30 | 2022-08-02 14:53:30 | 2022-08-02 14:53:30 | 2022-08-02 14:53:31 | NULL                                                                           | {"Unfinished backends":{"4393c992-5da1-4e9f-8b03-895dc0c96dbc":[]},"ScannedRows":65546,"TaskNumber":1,"All backends":{"4393c992-5da1-4e9f-8b03-895dc0c96dbc":[10002]},"FileNumber":1,"FileSize":548622} |
| 10103 | unique_table_with_null    | FINISHED | ETL:100%; LOAD:100% | SPARK  | unselected.rows=0; dpp.abnorm.ALL=0; dpp.norm.ALL=65546 | resource:test_spark_resource_07af473a_1230_11ed_b483_00163e0e550b; timeout(s):300; max_filter_ratio:0.0 | NULL     | 2022-08-02 14:56:06 | 2022-08-02 14:56:19 | 2022-08-02 14:56:41 | 2022-08-02 14:56:41 | 2022-08-02 14:56:44 | http://emr-header-1.cluster-49091:20888/proxy/application_1655710334658_26391/ | {"Unfinished backends":{"00000000-0000-0000-0000-000000000000":[]},"ScannedRows":65546,"TaskNumber":1,"All backends":{"00000000-0000-0000-0000-000000000000":[-1]},"FileNumber":1,"FileSize":8790855}   |
+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

示例三：`example_db` データベースのインポートジョブを確認します。インポートジョブのラベルには `table` という文字列が含まれている必要があり、`LoadStartTime` で降順に並べ替えます。

```plain
SHOW LOAD FROM example_db 
WHERE LABEL LIKE "table" 
ORDER BY LoadStartTime DESC;

+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| JobId | Label                     | State    | Progress            | Type   | EtlInfo                                                 | TaskInfo                                                                                                | ErrorMsg | CreateTime          | EtlStartTime        | EtlFinishTime       | LoadStartTime       | LoadFinishTime      | URL                                                                            | JobDetails                                                                                                                                                                                              |
+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 10103 | unique_table_with_null    | FINISHED | ETL:100%; LOAD:100% | SPARK  | unselected.rows=0; dpp.abnorm.ALL=0; dpp.norm.ALL=65546 | resource:test_spark_resource_07af473a_1230_11ed_b483_00163e0e550b; timeout(s):300; max_filter_ratio:0.0 | NULL     | 2022-08-02 14:56:06 | 2022-08-02 14:56:19 | 2022-08-02 14:56:41 | 2022-08-02 14:56:41 | 2022-08-02 14:56:44 | http://emr-header-1.cluster-49091:20888/proxy/application_1655710334658_26391/ | {"Unfinished backends":{"00000000-0000-0000-0000-000000000000":[]},"ScannedRows":65546,"TaskNumber":1,"All backends":{"00000000-0000-0000-0000-000000000000":[-1]},"FileNumber":1,"FileSize":8790855}   |
| 10082 | duplicate_table_with_null | FINISHED | ETL:100%; LOAD:100% | BROKER | unselected.rows=0; dpp.abnorm.ALL=0; dpp.norm.ALL=65546 | resource:N/A; timeout(s):300; max_filter_ratio:0.0                                                      | NULL     | 2022-08-02 14:53:27 | 2022-08-02 14:53:30 | 2022-08-02 14:53:30 | 2022-08-02 14:53:30 | 2022-08-02 14:53:31 | NULL                                                                           | {"Unfinished backends":{"4393c992-5da1-4e9f-8b03-895dc0c96dbc":[]},"ScannedRows":65546,"TaskNumber":1,"All backends":{"4393c992-5da1-4e9f-8b03-895dc0c96dbc":[10002]},"FileNumber":1,"FileSize":548622} |
+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

示例四：`example_db` データベースのインポートジョブを確認します。インポートジョブのラベルは `duplicate_table_with_null` で、状態は `FINISHED` である必要があります。

```plain
SHOW LOAD FROM example_db 
WHERE LABEL = "duplicate_table_with_null" AND STATE = "FINISHED";

+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+----------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| JobId | Label                     | State    | Progress            | Type   | EtlInfo                                                 | TaskInfo                                           | ErrorMsg | CreateTime          | EtlStartTime        | EtlFinishTime       | LoadStartTime       | LoadFinishTime      | URL  | JobDetails                                                                                                                                                                                              |
+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+----------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 10082 | duplicate_table_with_null | FINISHED | ETL:100%; LOAD:100% | BROKER | unselected.rows=0; dpp.abnorm.ALL=0; dpp.norm.ALL=65546 | resource:N/A; timeout(s):300; max_filter_ratio:0.0 | NULL     | 2022-08-02 14:53:27 | 2022-08-02 14:53:30 | 2022-08-02 14:53:30 | 2022-08-02 14:53:30 | 2022-08-02 14:53:31 | NULL | {"Unfinished backends":{"4393c992-5da1-4e9f-8b03-895dc0c96dbc":[]},"ScannedRows":65546,"TaskNumber":1,"All backends":{"4393c992-5da1-4e9f-8b03-895dc0c96dbc":[10002]},"FileNumber":1,"FileSize":548622} |
+-------+---------------------------+----------+---------------------+--------+---------------------------------------------------------+----------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
```

示例五：`example_db` データベースのインポートジョブを確認します。インポートジョブは `CreateTime` で昇順に並べ替えられ、オフセット1から2つの結果が表示されます。

```sql
SHOW LOAD FROM example_db 
ORDER BY CreateTime ASC 
LIMIT 2 OFFSET 1;
```

または

```sql
SHOW LOAD FROM example_db 
ORDER BY CreateTime ASC 
LIMIT 1,2;
```

結果は以下の通りです：

```plain
+-------+---------------------------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| JobId | Label                                       | State    | Progress            | Type   | EtlInfo                                                 | TaskInfo                                                                                                | ErrorMsg | CreateTime          | EtlStartTime        | EtlFinishTime       | LoadStartTime       | LoadFinishTime      | URL                                                                            | JobDetails                                                                                                                                                                                            |
+-------+---------------------------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| 10103 | unique_table_with_null                      | FINISHED | ETL:100%; LOAD:100% | SPARK  | unselected.rows=0; dpp.abnorm.ALL=0; dpp.norm.ALL=65546 | resource:test_spark_resource_07af473a_1230_11ed_b483_00163e0e550b; timeout(s):300; max_filter_ratio:0.0 | NULL     | 2022-08-02 14:56:06 | 2022-08-02 14:56:19 | 2022-08-02 14:56:41 | 2022-08-02 14:56:41 | 2022-08-02 14:56:44 | http://emr-header-1.cluster-49091:20888/proxy/application_1655710334658_26391/ | {"Unfinished backends":{"00000000-0000-0000-0000-000000000000":[]},"ScannedRows":65546,"TaskNumber":1,"All backends":{"00000000-0000-0000-0000-000000000000":[-1]},"FileNumber":1,"FileSize":8790855} |

| 10120 | insert_3a57b595-1230-11ed-b075-00163e14c85e | FINISHED | ETL:100%; LOAD:100% | INSERT | NULL                                                    | resource:N/A; timeout(s):3600; max_filter_ratio:0.0                                                     | NULL     | 2022-08-02 14:56:26 | 2022-08-02 14:56:26 | 2022-08-02 14:56:26 | 2022-08-02 14:56:26 | 2022-08-02 14:56:26 |                                                                                | {"Unfinished backends":{},"ScannedRows":0,"TaskNumber":0,"All backends":{},"FileNumber":0,"FileSize":0}                                                                                               |
+-------+---------------------------------------------+----------+---------------------+--------+---------------------------------------------------------+---------------------------------------------------------------------------------------------------------+----------+---------------------+---------------------+---------------------+---------------------+---------------------+--------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+