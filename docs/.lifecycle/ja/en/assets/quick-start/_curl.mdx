
StarRocks Stream Load と curl は多くの引数を取ります。このチュートリアルで使用される引数のみをここで説明し、残りの引数については詳細情報セクションでリンクを提供します。

#### `--location-trusted`

この設定により、curl はリダイレクトされた URL にも資格情報を渡すようになります。

#### `-u root`

StarRocks にログインする際に使用するユーザー名です。

#### `-T filename`

T は転送を意味し、転送するファイル名を指定します。

#### `label:name-num`

この Stream Load ジョブに関連付けるラベルです。ラベルは一意でなければならないため、ジョブを複数回実行する場合は、数値を追加してそれを増分させることができます。

#### `column_separator:,`

ファイルが単一の `,` を使用している場合は、上記のように設定します。異なる区切り文字を使用する場合は、その区切り文字をここで設定してください。一般的な選択肢は `\t`、`,`、`|` です。

#### `skip_header:1`

CSV ファイルには、すべての列名がリストされた単一のヘッダー行があるものがあり、データ型が記載された第二行が追加されているものもあります。ヘッダー行が1つまたは2つある場合は `1` または `2` に設定し、ヘッダー行がない場合は `0` に設定します。

#### `enclose:\"`

埋め込みコンマを含む文字列を二重引用符で囲むことが一般的です。このチュートリアルで使用されるサンプルデータセットにはコンマを含む地理的位置があるため、enclose 設定は `\"` に設定されています。`"` を `\` でエスケープすることを忘れないでください。

#### `max_filter_ratio:1`

これによりデータにいくつかのエラーが許容されます。理想的には `0` に設定され、エラーがあるとジョブは失敗します。デバッグ中にすべての行が失敗することを許容するために `1` に設定されています。

#### `columns:`

CSVファイルの列からStarRocksテーブルの列へのマッピングです。CSVファイルにはテーブルの列よりも多くの列があることがわかります。テーブルに含まれていない列はスキップされます。

また、`columns:` 行にはクラッシュデータセットのデータ変換が含まれていることに気付くでしょう。CSVファイルには標準に準拠していない日付と時刻が含まれていることがよくあります。これはクラッシュの日時のCSVデータをDATETIME型に変換するロジックです。

##### 列の行

これは1つのデータレコードの始まりです。日付は `MM/DD/YYYY` 形式で、時刻は `HH:MI` です。DATETIMEは通常 `YYYY-MM-DD HH:MI:SS` であるため、このデータを変換する必要があります。

```plaintext
08/05/2014,9:10,BRONX,10469,40.8733019,-73.8536375,"(40.8733019, -73.8536375)",
```

これは `columns:` パラメータの始まりです：

```bash
-H "columns:tmp_CRASH_DATE, tmp_CRASH_TIME, CRASH_DATE=str_to_date(concat_ws(' ', tmp_CRASH_DATE, tmp_CRASH_TIME), '%m/%d/%Y %H:%i')"
```

これによりStarRocksは以下を指示されます：
- CSVファイルの最初の列の内容を `tmp_CRASH_DATE` に割り当てる
- CSVファイルの2番目の列の内容を `tmp_CRASH_TIME` に割り当てる
- `concat_ws()` は `tmp_CRASH_DATE` と `tmp_CRASH_TIME` をスペースで区切って連結する
- `str_to_date()` は連結された文字列からDATETIMEを生成する
- 結果のDATETIMEを `CRASH_DATE` 列に格納する

