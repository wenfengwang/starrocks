---
displayed_sidebar: English
---

# Dataphin

Dataphinは、Alibaba GroupのOneDataデータガバナンス手法の内部実践をクラウドベースで提供するものです。ビッグデータのライフサイクル全体にわたるデータ統合、構築、管理、活用のワンストップソリューションを提供し、企業がデータガバナンスのレベルを大幅に向上させ、高品質で信頼性が高く、利便性が高く、安全かつ経済的な生産を実現するエンタープライズレベルのデータミドルプラットフォームの構築を支援します。Dataphinは、さまざまなコンピューティングプラットフォームのサポートと拡張可能なオープン機能を提供し、さまざまな業界の企業のプラットフォーム技術アーキテクチャと特定の要件を満たすことができます。

DataphinとStarRocksを統合する方法はいくつかあります：

- データ統合のためのソースまたはデスティネーションデータソースとして。StarRocksからデータを読み込んで他のデータソースにプッシュすることも、他のデータソースからデータをプルしてStarRocksに書き込むこともできます。

- Flink SQLおよびDataStream開発のソーステーブル（アンバウンドスキャン）、ディメンションテーブル（バウンドスキャン）、またはリザルトテーブル（ストリーミングシンクおよびバッチシンク）として。

- データウェアハウスまたはデータマートとして。StarRocksは、SQLスクリプト開発、スケジューリング、データ品質検出、セキュリティ識別、その他のデータリサーチおよびガバナンスタスクに使用できるコンピュートソースとして登録できます。

## データ統合

StarRocksデータソースを作成し、オフライン統合タスクでソースデータベースまたはデスティネーションデータベースとしてStarRocksデータソースを使用することができます。手順は以下の通りです。

### StarRocksデータソースの作成

#### 基本情報

![StarRocksデータソースの作成 - 1](../../assets/Dataphin/create_sr_datasource_1.png)

- **名前**: 必須。データソース名を入力してください。漢字、英字、数字、アンダースコア(_）、ハイフン(-)のみを含むことができ、64文字を超えることはできません。

- **データソースコード**: 任意。データソースコードを設定すると、`data_source_code.table`または`data_source_code.schema.table`の形式でデータソース内のFlink SQLを参照できます。対応する環境でデータソースに自動的にアクセスする場合は、`${data_source_code}.table`または`${data_source_code}.schema.table`の形式でアクセスします。

  > **注記**
  >
  > 現在、MySQL、Hologres、MaxComputeデータソースのみがサポートされています。

- **サポートシナリオ**: データソースが適用可能なシナリオ。

- **説明**: 任意。データソースの簡単な説明を入力できます。最大128文字まで可能です。

- **環境**: ビジネスデータソースが本番データソースと開発データソースを区別する場合は、**Prod and Dev**を選択します。ビジネスデータソースが本番と開発データソースを区別しない場合は、**Prod**を選択します。

- **タグ**: データソースにラベルを付けるためのタグを選択できます。

#### 構成情報

![StarRocksデータソースの作成 - 2](../../assets/Dataphin/create_sr_datasource_2.png)

- **JDBC URL**: 必須。形式は`jdbc:mysql://<host>:<port>/<dbname>`です。`host`はStarRocksクラスタのFE（フロントエンド）ホストのIPアドレス、`port`はFEのクエリポート、`dbname`はデータベース名です。

- **Load URL**: 必須。形式は`fe_ip:http_port;fe_ip:http_port`です。`fe_ip`はFE（フロントエンド）ホスト、`http_port`はFEのポートです。

- **ユーザー名**: 必須。データベースのユーザー名です。

- **パスワード**: 必須。データベースのパスワードです。

#### 詳細設定

![StarRocksデータソースの作成 - 3](../../assets/Dataphin/create_sr_datasource_3.png)

- **connectTimeout**: データベースの接続タイムアウト（ミリ秒）。デフォルト値は900,000ミリ秒（15分）です。

- **socketTimeout**: データベースのソケットタイムアウト（ミリ秒）。デフォルト値は1,800,000ミリ秒（30分）です。

### StarRocksデータソースからデータを読み取り、他のデータソースにデータを書き込む

#### StarRocks入力コンポーネントをオフライン統合タスクキャンバスにドラッグ

![StarRocksからデータを読み取る - 1](../../assets/Dataphin/read_from_sr_datasource_1.png)

#### StarRocks入力コンポーネントの設定

![StarRocksからデータを読み取る - 2](../../assets/Dataphin/read_from_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントのシナリオと位置に基づいて適切な名前を入力します。

- **データソース**: Dataphinで作成したStarRocksデータソースまたはプロジェクトを選択します。データソースの読み取り権限が必要です。満足できるデータソースがない場合は、データソースを追加するか、関連する権限を申請することができます。

- **ソーステーブル**: 入力と同じテーブル構造を持つ単一テーブルまたは複数テーブルを選択します。

- **テーブル**: ドロップダウンリストからStarRocksデータソースのテーブルを選択します。

- **スプリットキー**: 並列処理設定とともに使用します。ソースデータテーブルの列をスプリットキーとして使用できます。主キーやインデックス付き列をスプリットキーとして使用することを推奨します。

- **バッチ数**: 一括で抽出されるデータレコードの数です。

- **入力フィルタリング**: 任意。

  次の2つのケースでは、フィルター情報を入力する必要があります。
  
  - 特定のデータをフィルタリングしたい場合。
  - 日次でデータを増分的に追加する場合や、完全なデータを取得する場合は、Dataphinコンソールのシステム時刻として設定された日付を入力する必要があります。例えば、StarRocksのトランザクションテーブルでトランザクション作成日が`${bizdate}`として設定されている場合です。

- **出力フィールド**: 入力テーブル情報に基づいて関連フィールドをリストします。フィールドの名前を変更したり、削除したり、追加したり、移動したりすることができます。通常、フィールドはダウンストリームデータの可読性を高めるため、または出力時のフィールドマッピングを容易にするために名前が変更されます。アプリケーションシナリオで関連フィールドが不要な場合、入力段階でフィールドを削除することができます。フィールドの順序は変更されることがあり、これは複数の入力データがダウンストリームでマージされたり出力されたりする際に、異なる名前のフィールドを同じ行で効果的にマッピングするためです。

#### 出力コンポーネントを宛先データソースとして選択し、設定する

![StarRocksからデータを読み取る - 3](../../assets/Dataphin/read_from_sr_datasource_3.png)

### 他のデータソースからデータを読み取り、StarRocksデータソースにデータを書き込む

#### オフライン統合タスクで入力コンポーネントを構成し、StarRocks 出力コンポーネントを宛先データソースとして選択して設定します

![StarRocks にデータを書き込む - 1](../../assets/Dataphin/write_to_sr_datasource_1.png)

#### StarRocks 出力コンポーネントの設定

![StarRocks にデータを書き込む - 2](../../assets/Dataphin/write_to_sr_datasource_2.png)

- **ステップ名**: 現在のコンポーネントのシナリオと位置に基づいて適切な名前を入力します。

- **データソース**: StarRocks で作成した Dataphin データソースまたはプロジェクトを選択します。構成担当者が同期書き込み権限を持つデータソースです。データソースが要件を満たしていない場合は、データソースを追加するか、関連する権限を申請できます。

- **テーブル**: ドロップダウンリストから StarRocks データソースのテーブルを選択します。

- **ワンクリックでターゲットテーブルを生成**: StarRocks データソースにターゲットテーブルがまだ作成されていない場合、アップストリームから読み取ったフィールドの名前、型、備考を自動的に取得し、テーブル作成ステートメントを生成します。ワンクリックでターゲットテーブルを生成することができます。

- **CSV インポート列区切り文字**: StreamLoad CSV を使用してインポートします。CSV インポート列の区切り文字を設定できます。デフォルト値は `\t` です。ここではデフォルト値を指定しないでください。データ自体に `\t` が含まれている場合は、他の文字を区切り文字として使用する必要があります。

- **CSV インポート行区切り文字**: StreamLoad CSV を使用してインポートします。CSV インポート行の区切り文字を設定できます。デフォルト値は `\n` です。ここではデフォルト値を指定しないでください。データ自体に `\n` が含まれている場合は、他の文字を区切り文字として使用する必要があります。

- **パースソリューション**: オプション。データが StarRocks データソースに書き込まれる前後の特別な処理です。準備ステートメントはデータの書き込み前に実行され、完了ステートメントはデータの書き込み後に実行されます。

- **フィールドマッピング**: マッピングするフィールドを手動で選択するか、名前ベースまたは位置ベースのマッピングを使用して、アップストリーム入力のフィールドと宛先テーブルのフィールドに基づいて一度に複数のフィールドを処理できます。

## リアルタイム開発

### 簡単な紹介

StarRocks は、高速かつスケーラブルなリアルタイム分析データベースです。リアルタイムコンピューティングでは、リアルタイムデータ分析とクエリのニーズに応えるためにデータを読み書きするために一般的に使用されます。エンタープライズのリアルタイムコンピューティングシナリオで広く使用されており、リアルタイムビジネス監視と分析、リアルタイムユーザー行動分析、リアルタイム広告入札システム、リアルタイムリスク管理、不正防止、リアルタイム監視と早期警告などのアプリケーションシナリオで使用できます。データをリアルタイムで分析しクエリすることで、企業はビジネス状況を迅速に把握し、意思決定を最適化し、より良いサービスを提供し、利益を守ることができます。

### StarRocks コネクタ

StarRocks コネクタは以下の情報をサポートしています：

| **カテゴリ**                                           | **事実とデータ**                       |
| ------------------------------------------------------ | ------------------------------------------- |
| サポートされるタイプ                                        | ソーステーブル、ディメンションテーブル、結果テーブル |
| 実行モード                                           | ストリームモードとバッチモード                  |
| データフォーマット                                            | JSON と CSV                                |
| 特別なメトリクス                                        | なし                                        |
| API タイプ                                               | Datastream と SQL                          |
| 結果テーブルのデータ更新または削除をサポートしますか？ | はい                                         |

### 使い方は？

Dataphin は、リアルタイムコンピューティングの読み書きターゲットとして StarRocks データソースをサポートしています。StarRocks メタテーブルを作成し、それをリアルタイムコンピューティングタスクに使用できます：

#### StarRocks メタテーブルの作成

1. **Dataphin** > **R & D** > **Develop** > **Tables** に移動します。

2. **Create** をクリックしてリアルタイムコンピューティングテーブルを選択します。

   ![StarRocks メタテーブルの作成 - 1](../../assets/Dataphin/create_sr_metatable_1.png)

   - **テーブルタイプ**: **メタテーブル** を選択します。

   - **メタテーブル**: メタテーブルの名前を入力します。名前は変更不可です。

   - **データソース**: StarRocks データソースを選択します。

   - **ディレクトリ**: テーブルを作成するディレクトリを選択します。

   - **説明**: オプション。

   ![StarRocks メタテーブルの作成 - 2](../../assets/Dataphin/create_sr_metatable_2.png)

3. メタテーブルを作成した後、データソース、ソーステーブル、メタテーブルフィールドの変更、メタテーブルパラメータの設定など、メタテーブルを編集できます。

   ![StarRocks メタテーブルの編集](../../assets/Dataphin/edit_sr_metatable_1.png)

4. メタテーブルを提出します。

#### Kafka から StarRocks へリアルタイムでデータを書き込む Flink SQL タスクを作成する

1. **Dataphin** > **R & D** > **Develop** > **Computing Tasks** にアクセスします。

2. **Create Flink SQL task** をクリックします。

   ![Flink SQL タスクの作成 - ステップ 2](../../assets/Dataphin/create_flink_task_step2.png)

3. Flink SQL コードを編集し、プリコンパイルします。Kafka メタテーブルは入力テーブルとして、StarRocks メタテーブルは出力テーブルとして使用されます。

   ![Flink SQL タスクの作成 - ステップ 3 - 1](../../assets/Dataphin/create_flink_task_step3-1.png)
   ![Flink SQL タスクの作成 - ステップ 3 - 2](../../assets/Dataphin/create_flink_task_step3-2.png)

4. プリコンパイルが成功したら、コードをデバッグして提出します。

5. 開発環境でのテストは、ログを出力し、テストテーブルに書き込むことで実行できます。テストテーブルは、メタテーブル > プロパティ > デバッグテスト設定で設定できます。

   ![Flink SQL タスクの作成 - ステップ 5 - 1](../../assets/Dataphin/create_flink_task_step5-1.png)
   ![Flink SQL タスクの作成 - ステップ 5 - 2](../../assets/Dataphin/create_flink_task_step5-2.png)

6. 開発環境でタスクが正常に実行されたら、タスクと使用するメタテーブルを本番環境に公開します。

   ![Flink SQL タスクの作成 - ステップ 6](../../assets/Dataphin/create_flink_task_step6.png)

7. 本番環境でタスクを開始し、Kafka から StarRocks へリアルタイムでデータを書き込みます。実行中の分析で各メトリックのステータスとログを確認し、タスクの実行状況を把握したり、タスクのモニタリングアラートを設定したりできます。

   ![Flink SQL タスクの作成 - ステップ 7 - 1](../../assets/Dataphin/create_flink_task_step7-1.png)
   ![Flink SQL タスクの作成 - ステップ 7 - 2](../../assets/Dataphin/create_flink_task_step7-2.png)

## データウェアハウスまたはデータマート

### 前提条件

- StarRocks のバージョンは 3.0.6 以降です。

- Dataphin がインストールされており、Dataphin のバージョンは 3.12 以降です。

- 統計収集を有効にする必要があります。StarRocks をインストールした後、デフォルトで収集が有効になっています。詳細については、[CBO のための統計収集](../../using_starrocks/Cost_based_optimizer.md)を参照してください。

- StarRocks の内部カタログ（デフォルトカタログ）はサポートされていますが、外部カタログはサポートされていません。

### 接続設定

#### メタデータウェアハウスの設定

Dataphin はメタデータに基づいて情報を表示し、テーブルの使用情報やメタデータの変更を提示できます。StarRocks を使用してメタデータの処理と計算を行うことができます。そのため、使用する前にメタデータコンピューティングエンジン（メタデータウェアハウス）を初期化する必要があります。手順は以下の通りです：

1. 管理者アカウントで Dataphin メタデータウェアハウステナントにログインします。

2. 「管理」>「システム」>「メタデータウェアハウス設定」に進みます。

   a. 「開始」をクリックします。

   b. StarRocks を選択します。

   c. パラメータを設定します。テスト接続に成功したら、「次へ」をクリックします。

   d. メタウェアハウスの初期化を完了します。

   ![メタデータウェアハウスの設定](../../assets/Dataphin/metadata_warehouse_settings_1.png)

パラメータは以下の通りです：

- **JDBC URL**: JDBC 接続文字列は二部分に分かれています：

  - パート I: 形式は `jdbc:mysql://<Host>:<Port>/` です。`Host` は StarRocks クラスタ内の FE ホストの IP アドレス、`Port` は FE のクエリポートです。デフォルト値：`9030`。

  - パート II: 形式は `database?key1=value1&key2=value2` で、`database` はメタデータ計算に使用される StarRocks データベースの名前で、必須です。`?` の後のパラメータはオプションです。

- **Load URL**: 形式は `fe_ip:http_port;fe_ip:http_port` です。`fe_ip` は FE（フロントエンド）のホスト、`http_port` は FE のポートです。

- **Username**: StarRocks に接続するためのユーザー名。

  ユーザーは JDBC URL で指定されたデータベースに対する読み書き権限を持ち、以下のデータベースとテーブルへのアクセス権限が必要です：

  - Information_Schema のすべてのテーブル

  - _statistics_.column_statistics

  - _statistics_.table_statistics_v1

- **Password**: StarRocks の接続パスワード。

- **Meta Project**: Dataphin 内でメタデータ処理に使用されるプロジェクト名。Dataphin システム内でのみ使用されます。プロジェクト名には `dataphin_meta` を推奨します。

#### StarRocks プロジェクトの作成とデータ開発の開始

データ開発を開始するためには、以下の手順に従ってください：

1. コンピューティング設定を行います。

2. StarRocks の計算ソースを作成します。

3. プロジェクトを作成します。

4. StarRocks SQL タスクを作成します。

##### コンピューティング設定

コンピューティング設定では、テナントのコンピューティングエンジンの種類とクラスターアドレスを設定します。詳細な手順は以下の通りです：

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. 「管理」>「システム」>「計算設定」に進みます。

3. StarRocks を選択し、「次へ」をクリックします。

4. JDBC URL を入力し、検証します。JDBC URL の形式は `jdbc:mysql://<Host>:<Port>/` です。`Host` は StarRocks クラスタ内の FE ホストの IP アドレス、`Port` は FE のクエリポートです。デフォルト値：`9030`。

##### StarRocks 計算ソース

計算ソースは Dataphin の概念で、Dataphin プロジェクトスペースを StarRocks のストレージ計算スペース（データベース）にバインドして登録することが主な目的です。各プロジェクトに対して計算ソースを作成する必要があります。詳細な手順は以下の通りです：

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. 「計画」>「エンジン」に進みます。

3. 右上隅にある「計算エンジンの追加」をクリックして計算ソースを作成します。

詳細な設定情報は以下の通りです：

1. **基本情報**

   ![計算エンジンの作成 - 1](../../assets/Dataphin/create_compute_engine_1.png)

   - **計算エンジンの種類**: StarRocks を選択します。

   - **計算エンジン名**: 作成するプロジェクトと同じ名前を使用することを推奨します。開発プロジェクトの場合は、接尾辞 `_dev` を追加します。

   - **説明**: 任意。計算ソースの説明を入力します。

2. **設定情報**

   ![計算エンジンの作成 - 2](../../assets/Dataphin/create_compute_engine_2.png)

   - **JDBC URL**: 形式は `jdbc:mysql://<Host>:<Port>/` です。`Host` は StarRocks クラスタ内の FE ホストの IP アドレス、`Port` は FE のクエリポートです。デフォルト値：`9030`。

   - **Load URL**: 形式は `fe_ip:http_port;fe_ip:http_port` です。`fe_ip` は FE（フロントエンド）のホスト、`http_port` は FE のポートです。

   - **Username**: StarRocks に接続するためのユーザー名。

   - **Password**: StarRocks のパスワード。

   - **Task Resource Group**: 優先度の異なるタスクに対して異なる StarRocks リソースグループを指定できます。リソースグループを指定しない場合、StarRocks エンジンが実行するリソースグループを決定します。リソースグループを指定する場合、Dataphin によって指定されたリソースグループに優先順位の異なるタスクが割り当てられます。SQL タスクのコードや論理テーブルのマテリアライズ設定でリソースグループが指定されている場合、タスク実行時に計算ソースタスクのリソースグループ設定は無視されます。

   ![計算エンジンの作成 - 3](../../assets/Dataphin/create_compute_engine_3.png)

##### Dataphin プロジェクト

計算ソースを作成したら、Dataphin プロジェクトにバインドできます。Dataphin プロジェクトはプロジェクトメンバー、StarRocks のストレージおよび計算スペースを管理し、計算タスクを管理および保守します。

Dataphin プロジェクトを作成するには、以下の手順に従います：

1. システム管理者またはスーパー管理者として Dataphin にログインします。

2. 「計画」>「プロジェクト管理」に進みます。

3. 右上隅の「プロジェクトの作成」をクリックしてプロジェクトを作成します。

4. 基本情報を入力し、オフラインエンジンから前の手順で作成した StarRocks エンジンを選択します。

5. 「作成」をクリックします。

##### StarRocks SQL

プロジェクトを作成したら、StarRocks SQL タスクを作成して StarRocks で DDL または DML 操作を実行できます。

詳細な手順は次のとおりです。

1. **R & D** > **Develop** へ移動します。

2. 右上隅の「+」をクリックして、StarRocks SQLタスクを作成します。

   ![Dataphin プロジェクトの設定 - 1](../../assets/Dataphin/configure_dataphin_project_1.png)

3. 名前とスケジューリングタイプを入力してSQLタスクを作成します。

4. エディタにSQLを入力して、StarRocksでDDLおよびDML操作を開始します。

   ![Dataphin プロジェクトの設定 - 2](../../assets/Dataphin/configure_dataphin_project_2.png)
