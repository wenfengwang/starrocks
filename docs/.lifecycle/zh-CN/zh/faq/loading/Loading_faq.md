---
displayed_sidebar: "中文"
---

# 通用常见问题导入指南

## 1. 遇到 "关闭索引通道失败" 和 "平板版本过多" 的错误该如何处理？

上述错误是由于导入频率过快，数据未能及时进行合并（Compaction），导致版本数量超过了系统支持的最大未合并版本数。默认情况下，系统支持的最大未合并版本数为 1000。为解决上述错误，可以采取以下方法：

- 增加每次导入的数据量，降低导入频率。

- 在 BE 配置文件 **be.conf** 中, 修改以下配置项以调整合并策略，以加快合并速度：

    ```Plain
    累积合并线程数每盘 = 4
    基础合并线程数每盘 = 2
    累积合并检查间隔秒数 = 2
    ```

  修改完成后，需要监测内存和 I/O 使用情况，确保系统的内存和 I/O 使用情况正常。

## 2. 遇到 "Label Already Exists" 的错误该如何处理？

在 StarRocks 集群中，同一个数据库内存在一个已成功执行或正在执行的带有相同标签的导入作业。原因分析如下：

由于 Stream Load 使用 HTTP 协议提交导入作业请求，通常情况下，各种语言的 HTTP 客户端都会带有请求重试机制。在 StarRocks 集群接收到第一个请求并开始处理 Stream Load 作业后，如果未及时向客户端返回结果，客户端可能会重试并再次发送相同请求。这种情况下，第二个相同请求会因为第一个请求已在处理中，而返回 `Label Already Exists` 状态提示。

需要检查是否存在导入方式之间的标签冲突或重复提交的导入作业。排查方法包括：

- 检索主 FE 日志中的标签，查看是否有重复出现的情况。如果有，那么意味着客户端重复提交了请求。

  > **说明**
  >
  > StarRocks 集群中的导入作业标签不区分导入方式。因此，不同的导入作业可能使用了相同的标签。

- 执行 SHOW LOAD WHERE LABEL = "xxx" 语句，查看是否存在带有相同标签并且状态为 **FINISHED** 的导入作业。

  > **说明**
  >
  > 其中 `xxx` 为待检查的标签字符串。

建议根据当前请求导入的数据量估算大致的导入耗时，并根据导入超时时间合理调整客户端请求的超时时间，以避免客户端多次提交相同的请求。

## 3. 发生数据质量错误 "ETL_QUALITY_UNSATISFIED; msg:quality not good enough to cancel" 时该如何处理？

执行 [SHOW LOAD](../../sql-reference/sql-statements/data-manipulation/SHOW_LOAD.md) 语句，查找返回信息中的 URL，然后查看错误数据。

常见的数据质量错误包括：

- "转换 CSV 字符串为 INT 失败。"
  
  源数据文件中的字符串在转换为对应数据类型时出错。例如，尝试将 `abc` 转换为数字时失败。

- "输入长度过长，超出了模式。"
  
  源数据文件中的某列长度不正确。比如定长字符串超出表创建时设置的长度，或 INT 类型字段超出了 4 个字节。

- "实际列数量少于模式定义的列数量。"
  
  根据指定的分隔符划分后，源数据文件中的某一行的列数小于指定的列数。可能原因是分隔符设置不正确。

- "实际列数量多于模式定义的列数量。"
  
  根据指定的分隔符划分后，源数据文件中的某一行的列数大于指定的列数。

- "小数部分的长度超出了模式定义的比例。"
  
  源数据文件中的某个 DECIMAL 类型列的小数部分超出了指定的长度。

- "整数部分的长度超出了模式定义的精度。"
  
  源数据文件中的某个 DECIMAL 类型列的整数部分超出了指定的长度。
  
- "分区键没有对应的分区。"
  
  源数据文件中的某行数据的分区列值不在任何分区的范围内。

## 4. 在导入过程中遇到 RPC 超时应该怎么办？

检查 BE 配置文件 **be.conf** 中 `write_buffer_size` 参数的配置。该参数用于控制 BE 上内存写入块的最大大小，默认值为 100 MB。如果设置值过大，可能会导致远程过程调用（Remote Procedure Call，简称RPC）超时。此时，需要结合 BE 配置文件中的 `tablet_writer_rpc_timeout_sec` 参数适当调整 `write_buffer_size` 参数的值。参见 [BE 配置](../../loading/Loading_intro.md#be-配置)。

## 5. 导入任务报错 "Value count does not match column count" 应该如何处理？

导入任务失败，并且通过查看错误详情的 URL 发现返回了 "Value count does not match column count" 错误，表明解析源数据得到的列数与目标表的列数不一致：

```Java
错误：值数量与列数量不匹配。预期为 3，但实际为 1。行：2023-01-01T18:29:00Z,cpu0,80.99
错误：值数量与列数量不匹配。预期为 3，但实际为 1。行：2023-01-01T18:29:10Z,cpu1,75.23
错误：值数量与列数量不匹配。预期为 3，但实际为 1。行：2023-01-01T18:29:20Z,cpu2,59.44
```

造成这个错误的原因是导入命令或导入语句中指定的列分隔符与源数据文件中的列分隔符不一致。例如，在上述示例中，源数据为 CSV 格式，包含三列，列分隔符为逗号(`,`)，但是在导入命令或导入语句中却错误地指定了制表符(`\t`)作为列分隔符，导致原本的三列数据被错误解析为一列数据。

将导入命令或导入语句中的列分隔符更改为逗号(`,`)，然后再次尝试执行导入。